{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d4581b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+--------------------+\n",
      "| id|                nome|           descricao|       data_ingestao|\n",
      "+---+--------------------+--------------------+--------------------+\n",
      "|  1|Credit Card - Ols...|Southern black vi...|2025-04-28 15:49:...|\n",
      "|  2|Checking - Hill, ...|Service happy aga...|2025-04-28 15:49:...|\n",
      "|  3|Cash - Morris, Ce...|Something evening...|2025-04-28 15:49:...|\n",
      "|  4|Savings - Meyer, ...|Difficult Mrs hug...|2025-04-28 15:49:...|\n",
      "|  5|Checking - Durham...|Manager anyone sh...|2025-04-28 15:49:...|\n",
      "+---+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---+-------------+-------+--------------------+\n",
      "| id|         nome|   tipo|       data_ingestao|\n",
      "+---+-------------+-------+--------------------+\n",
      "|  1|Reimbursement|entrada|2025-04-28 15:50:...|\n",
      "|  2|Rental Income|entrada|2025-04-28 15:50:...|\n",
      "|  3|  Investments|entrada|2025-04-28 15:50:...|\n",
      "|  4| Subscription|saida  |2025-04-28 15:50:...|\n",
      "|  5|   Healthcare|saida  |2025-04-28 15:50:...|\n",
      "+---+-------------+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---+--------+------------+----------+--------------------+-------+-------------------+--------------------+\n",
      "| id|conta_id|categoria_id|      data|           descricao|  valor|       data_criacao|       data_ingestao|\n",
      "+---+--------+------------+----------+--------------------+-------+-------------------+--------------------+\n",
      "|  1|      39|          32|2024-08-19|Because official ...|4169.85|2025-04-16 15:42:36|2025-04-28 15:50:...|\n",
      "|  2|      37|           5|2025-01-10|Add hand face him...|-339.54|2025-04-16 15:42:36|2025-04-28 15:50:...|\n",
      "|  3|      38|          17|2025-03-28|    Paper and green.|-264.67|2025-04-16 15:42:36|2025-04-28 15:50:...|\n",
      "|  4|      39|           3|2025-01-11|Option street cou...|4009.89|2025-04-16 15:42:37|2025-04-28 15:50:...|\n",
      "|  5|      39|          12|2024-06-05|Culture gas dream...|4889.52|2025-04-16 15:42:37|2025-04-28 15:50:...|\n",
      "+---+--------+------------+----------+--------------------+-------+-------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, DataFrame\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "DB_CONFIG = {\n",
    "    \"host\": \"mysql-financial-db.c3imkkke2ssh.us-east-2.rds.amazonaws.com\",\n",
    "    \"user\": \"admin\",\n",
    "    \"password\": \"F(VD]Qe8r!BOCg72\",\n",
    "    \"database\": \"financial_db\"\n",
    "}\n",
    "\n",
    "def create_spark_session() -> SparkSession:\n",
    "    return (\n",
    "        SparkSession\n",
    "        .builder\n",
    "        .appName(\"MySQL to DataFrame\")  # type: ignore\n",
    "        .config(\"hive.exec.dynamic.partition.mode\", \"nonstrict\")\n",
    "        .config(\"hive.exec.dynamic.partition\", \"true\")\n",
    "        .config(\"spark.jars.packages\", \"mysql:mysql-connector-java:8.0.32\")\n",
    "        .master(\"local[*]\")\n",
    "        .getOrCreate()\n",
    "    )\n",
    "\n",
    "def read_mysql_table(spark: SparkSession, table_name: str, db_config: dict) -> DataFrame:\n",
    "    return (\n",
    "        spark\n",
    "        .read\n",
    "        .format(\"jdbc\")\n",
    "        .option(\"driver\", \"com.mysql.cj.jdbc.Driver\")\n",
    "        .option(\"url\", f\"jdbc:mysql://{db_config['host']}/{db_config['database']}\")\n",
    "        .option(\"user\", db_config[\"user\"])\n",
    "        .option(\"password\", db_config[\"password\"])\n",
    "        .option(\"dbtable\", table_name)\n",
    "        .load()\n",
    "    )\n",
    "\n",
    "def processar_tabela(spark: SparkSession, tabela: str):\n",
    "    df = read_mysql_table(spark, tabela, DB_CONFIG)\n",
    "    df = df.withColumn(\"data_ingestao\", F.current_timestamp())\n",
    "    \n",
    "    df.write.insertInto(f\"walter_araujo_database_sor.{tabela}\", overwrite=True)\n",
    "\n",
    "def main():\n",
    "    spark = create_spark_session()\n",
    "\n",
    "    tabelas = [\"contas\", \"categorias\", \"transacoes\"]\n",
    "\n",
    "    for tabela in tabelas:\n",
    "        processar_tabela(spark, tabela)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from traceback import format_exc\n",
    "    try:\n",
    "        main()\n",
    "    except:\n",
    "        print(format_exc())\n",
    "        exit(1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
