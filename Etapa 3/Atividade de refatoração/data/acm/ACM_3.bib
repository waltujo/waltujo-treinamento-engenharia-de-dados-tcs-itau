@inproceedings{10.1145/2905055.2905099,title = {Big data and ICT applications: A study}, author = {Misra Rachita , Panda Bijayalaxmi , Tiwary Mayank },year = {2016}, isbn = {9781450339629}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/2905055.2905099}, doi = {10.1145/2905055.2905099}, abstract = {Big Data is used to manage the data due to their large size and complexity, because it can't be handled with the traditional methods and the current technology or tools used for that. Big Data mining is populated with 5 V's volume, variability, velocity, variety, value which has the ability of retrieving important information from the huge data storage. Now the challenge of Big Data is becoming the opportunities of research for the next few years. Throughout the world researchers and developers are trying to make use of the Big Data technology to extend the ICT applications from the traditional LAN, WAN environment to Internet on cloud with Big Data. In this scenario this paper provides and an overview of some of the ICT applications which take advantage of data mining and analytics for big data. The paper tries to establish the wide range of applications of big data in ICT with the currently available data mining & data analytics platforms, languages and tools. An effort has been made to analyze the challenges faced in the different application fields. Some of the advances in the Big Data technology research that can help solve some of these challenges in ICT applications have been discussed in brief.}, location = {Udaipur, India}, series = {ICTCS '16}, pages = {1\u20136}, numpages = {6}, keywords = {Big data analytics, ICT, Big data, Hadoop, HDFS}}
@inproceedings{10.1145/3209978.3210213,title = {Big Data at Didi Chuxing}, author = {Ye Jieping },year = {2018}, isbn = {9781450356572}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3209978.3210213}, doi = {10.1145/3209978.3210213}, abstract = {Didi Chuxing is the largest ride-sharing platform in China, providing transportation services for over 400 million users. Every day, Didi Chuxing's platform generates over 100 TB worth of data, processes more than 40 billion routing requests, and produces over 15 billion location points. In this talk, I will explain how Didi Chuxing applies big data and AI technologies to analyze big transportation data and improve the travel experience for millions of users.}, location = {Ann Arbor, MI, USA}, series = {SIGIR '18}, pages = {1341}, numpages = {1}, keywords = {ai, transportation, big data}}
@inproceedings{10.1145/2593882.2593889,title = {Engineering big data solutions}, author = {Mockus Audris },year = {2014}, isbn = {9781450328654}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/2593882.2593889}, doi = {10.1145/2593882.2593889}, abstract = {Structured and unstructured data in operational support tools have long been prevalent in software engineering. Similar data is now becoming widely available in other domains. Software systems that utilize such operational data (OD) to help with software design and maintenance activities are increasingly being built despite the difficulties of drawing valid conclusions from disparate and low-quality data and the continuing evolution of operational support tools. This paper proposes systematizing approaches to the engineering of OD-based systems. To prioritize and structure research areas we consider historic developments, such as big data hype; synthesize defining features of OD, such as confounded measures and unobserved context; and discuss emerging new applications, such as diverse and large OD collections and extremely short development intervals. To sustain the credibility of OD-based systems more research will be needed to investigate effective existing approaches and to synthesize novel, OD-specific engineering principles.}, location = {Hyderabad, India}, series = {FOSE 2014}, pages = {85\u201399}, numpages = {15}, keywords = {Analytics, Data Quality, Game Theory, Data Engineering, Statistics, Data Science, Operational Data}}
@inproceedings{10.1145/3010089.3010144,title = {Mixture Model Approaches to Big Data Clustering and Classification}, author = {Hamdan Hani },year = {2016}, isbn = {9781450347792}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3010089.3010144}, doi = {10.1145/3010089.3010144}, abstract = {Technological evolution leads to increasingly large and heterogeneous data acquisitions (signals, images, measurement results, texts, etc.), and the growing share of information technology and digital simulation leads to the production of increasingly important quantities of data. This is the case for example in web mining, in biology with the sequencing of different genomes, in astronomy with the proliferation of images from probes or observatories, in meteorology with the simulation of atmospheric phenomena and their visualization, in environmental studies with earth observations, or also in social and human sciences with the digitization of corpus and dictionaries. In such contexts, the formalism of binned data is perfectly suited to deal with the massive data issues. This is particularly interesting in many industrial applications where conventional processing algorithms induce unreasonable computation times. In this talk, the importance and advantages of binning data, in big data clustering and classification, will be shown. Then, the fundamental and basic concepts of mixture models estimation from binned data will be presented. A special attention will be paid to the binned-EM algorithm and the bin-EM-CEM algorithm, and their application to data clustering and classification. A feedback on the implementation and use of these algorithms will be provided. In addition, some hard and open problems (data heterogeneity, new data structures and types, imprecision and variability of data, validation of the obtained partition structure, model selection, choice of the clusters number, etc.) and some promising solutions will be suggested. In order to show the usefulness of the presented approaches, some examples from real applications will be illustrated.}, location = {Blagoevgrad, Bulgaria}, series = {BDAW '16}, pages = {1\u20132}, numpages = {2}, keywords = {binned EM algorithm, semi fuzzy clustering, classification, mixture model, bin-EM-CEM algorithm, binned uncertain data, fuzzy clustering, binned data, Big data, clustering}}
@inproceedings{10.1145/3148055.3148057,title = {Big Data Aware Virtual Machine Placement in Cloud Data Centers}, author = {Hall Logan , Harris Bryan , Tomes Erica , Altiparmak Nihat },year = {2017}, isbn = {9781450355490}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3148055.3148057}, doi = {10.1145/3148055.3148057}, abstract = {While society continues to be transformed by insights from processing big data, the increasing rate at which this data is gathered is making processing in private clusters obsolete. A vast amount of big data already resides in the cloud, and cloud infrastructures provide a scalable platform for both the computational and I/O needs of big data processing applications. Virtualization is used as a base technology in the cloud; however, existing virtual machine placement techniques do not consider data replication and I/O bottlenecks of the infrastructure, yielding sub-optimal data retrieval times. This paper targets efficient big data processing in the cloud and proposes novel virtual machine placement techniques, which minimize data retrieval time by considering data replication, storage performance, and network bandwidth. We first present an integer-programming based optimal virtual machine placement algorithm and then propose two low cost data- and energy-aware virtual machine placement heuristics. Our proposed heuristics are compared with optimal and existing algorithms through extensive evaluation. Experimental results provide strong indications for the superiority of our proposed solutions in both performance and energy, and clearly outline the importance of big data aware virtual machine placement for efficient processing of large datasets in the cloud.}, location = {Austin, Texas, USA}, series = {BDCAT '17}, pages = {209\u2013218}, numpages = {10}, keywords = {storage systems, virtualization, big data, cloud computing}}
@inproceedings{10.1145/3456389,title = {2021 Workshop on Algorithm and Big Data},year = {2021}, isbn = {9781450389945}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, location = {Fuzhou, China}}
@inproceedings{10.1145/3264560.3266428,title = {A Scalable Streaming Big Data Architecture for Real-Time Sentiment Analysis}, author = {Ayvaz Serkan , Shiha Mohammed O. },year = {2018}, isbn = {9781450364744}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3264560.3266428}, doi = {10.1145/3264560.3266428}, abstract = {The systems with a short window of opportunity for actions and decisions require developing solutions providing real-time streaming analytics. Real-time big data streaming analytics is a challenging task. In this paper, we propose a streaming big data architecture for real-time social network analysis. As a case study, we investigated the relation between the public opinions on social media about cryptocurrencies and the changes in their prices using lexicon-based sentiment analysis approaches with the goal of assessing the feasibility of predicting the prices of cryptocurrencies. Two different approaches with two lexicons were used for sentiment analysis score calculations to assess the consistency of correlation measures on the collected dataset. Our model indicates that the prediction of cryptocurrency price changes using lexicon-based sentiment analysis methods is not reliable.}, location = {Barcelona, Spain}, series = {ICCBDC'18}, pages = {47\u201351}, numpages = {5}, keywords = {sentiment analysis, opinion mining, cryptocurrency, data streaming, big data}}
@inproceedings{10.1145/3492324.3494169,title = {Evaluating Serverless Architecture for Big Data Enterprise Applications}, author = {Bhat Aimer , Park Heeki , Roy Madhumonti },year = {2021}, isbn = {9781450391641}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3492324.3494169}, doi = {10.1145/3492324.3494169}, abstract = {Migration of enterprise applications to the cloud has been driven by a myriad of benefits ranging from availability of infinite computing resources to the elimination of upfront CapEx cost. However, many users still face the burden of complex framework knowledge requirement to efficiently deploy applications in the cloud. In this paper, we investigate serverless computing for performing large scale data processing with cloud-native primitives. Serverless computing environment abstracts all infrastructure handling, simplifying developers\u2019 work who aspire to deploy applications on the cloud. With dynamic input load on the system, serverless architecture has promise to provide better resource utilization and lower costs.}, location = {Leicester, United Kingdom}, series = {BDCAT '21}, pages = {1\u20138}, numpages = {8}, keywords = {Enterprise applications, Function as a Service, Big data processing, AWS Lambda, MapReduce, cloud computing, Serverless computing, load variations}}
@inproceedings{10.1145/3158335,title = {Big Data, Digitization, and Social Change: Big Data (Ubiquity symposium)}, author = {Johnson Jeffrey , Denning Peter , Sousa-Rodrigues David , Delic Kemal A. },year = {2017}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3158335}, doi = {10.1145/3158335}, abstract = {We use the term \"big data\" with the understanding that the real game changer is the connection and digitization of everything. Every portfolio is affected: finance, transport, housing, food, environment, industry, health, welfare, defense, education, science, and more. The authors in this symposium will focus on a few of these areas to exemplify the main ideas and issues.}, pages = {1\u20138}, numpages = {8}}
@inproceedings{10.1145/2939672.2945385,title = {IoT Big Data Stream Mining}, author = {De Francisci Morales Gianmarco , Bifet Albert , Khan Latifur , Gama Joao , Fan Wei },year = {2016}, isbn = {9781450342322}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/2939672.2945385}, doi = {10.1145/2939672.2945385}, abstract = {The challenge of deriving insights from the Internet of Things (IoT) has been recognized as one of the most exciting and key opportunities for both academia and industry. Advanced analysis of big data streams from sensors and devices is bound to become a key area of data mining research as the number of applications requiring such processing increases. Dealing with the evolution over time of such data streams, i.e., with concepts that drift or change completely, is one of the core issues in IoT stream mining. This tutorial is a gentle introduction to mining IoT big data streams. The first part introduces data stream learners for classification, regression, clustering, and frequent pattern mining. The second part deals with scalability issues inherent in IoT applications, and discusses how to mine data streams on distributed engines such as Spark, Flink, Storm, and Samza.}, location = {San Francisco, California, USA}, series = {KDD '16}, pages = {2119\u20132120}, numpages = {2}, keywords = {data streams, big data, IoT, data science}}
@inproceedings{10.1145/2331042.2331057,title = {Big data platforms: What's next?}, author = {Borkar Vinayak R. , Carey Michael J. , Li Chen },year = {2012}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/2331042.2331057}, doi = {10.1145/2331042.2331057}, abstract = {Three computer scientists from UC Irvine address the question \"What's next for big data?\" by summarizing the current state of the big data platform space and then describing ASTERIX, their next-generation big data management system.}, pages = {44\u201349}, numpages = {6}}
@inproceedings{10.1145/3206157.3206160,title = {Big Data Opportunities for Disease Outbreaks Detection in Global Mass Gatherings}, author = {Alshammari Sultanah M. , Mikler Armin M. },year = {2018}, isbn = {9781450363587}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3206157.3206160}, doi = {10.1145/3206157.3206160}, abstract = {The different mass gatherings occurring all over the world, such as sports and religious events, pose public health concerns due to the increased risk of transmitting infectious diseases in these settings. When these events are concluded, the travel patterns of the returning international participants could further contribute to a rapid spread of infectious diseases causing global epidemics. The need to establish real-time disease outbreak surveillance at global mass gatherings motivates new technologies and advanced computational methods. The rapid expansion of digital devices and access to internet applications among participants in these gatherings generate a massive amount of data. Once being collected and processed, these data along with other health-related data can make significant contributions to improve disease surveillance systems at global mass gatherings. In this paper, we present an overview of the main existing approaches for monitoring outbreaks of infectious diseases in these events and illustrate the perspectives and opportunities of Big Data in these application areas.}, location = {Honolulu, HI, USA}, series = {ICBDE '18}, pages = {16\u201321}, numpages = {6}, keywords = {Wireless Sensors, Disease Surveillance, Computational Modeling, Internet Data, Mass Gatherings, Infectious Disease, Epidemic, Outbreak, Syndromic Surveillance System, Big Data}}
@inproceedings{10.1145/3396452.3396464,title = {Innovation and Application of College Students' Education and Management Based on Big Data}, author = {Chen Chongyang , Xu Wei },year = {2020}, isbn = {9781450374989}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3396452.3396464}, doi = {10.1145/3396452.3396464}, abstract = {With the rapid development and popularization of big data technology in the world and the world's vigorous promotion of informatization, the education and management of college students are facing new opportunities and challenges. This paper takes the innovation and application of big data technology in college students' education and management as the core, analyzes the significance and advantages of big data in the education and management of college students, and deeply studies the innovative application of big data from the aspects of education and management resource sharing, digital education and management and open education and management. In addition, It will take the innovative application of big data in college information announcement system as an example to comprehensively improve the level of college students' education and management by big data mining in the system and other ways.}, location = {London, United Kingdom}, series = {ICBDE '20}, pages = {5\u20139}, numpages = {5}, keywords = {college, education and management, application, big data, innovation}}
@inproceedings{10.1145/3538950.3538954,title = {Information Intelligence System Solution Based on Big Data Flink Technology}, author = {Xu Baolin , Jiang Jin , Ye Junbin },year = {2022}, isbn = {9781450395632}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3538950.3538954}, doi = {10.1145/3538950.3538954}, abstract = {[Purpose/Significance] This paper aims to discuss how to use big data Flink technology to develop information intelligence system, and provides a reference case for developing information intelligence system using big data real-time streaming technology. [Design/Methodology] This paper briefly introduces the basic concepts of big data, batch processing, stream processing, Flink technology and its superiority in real-time stream processing. And then, according to the thinking mode of big data, complete a set of technical framework for processing information intelligence system [Findings/Conclusion] Compared with some other big data processing technologies such as Spark , Storm, Flink technology has obvious performance advantages in processing real-time stream information. [Originality/Value] Based on the big data thinking mode and the general process of big data processing, the research team creatively proposed an information intelligence processing system solution based on big data Flink technology. The solution takes Flink streaming technology as the processing center, Kafka as the message transmission queue, Elasticsearch as the real-time search engine, Kibana as the front-end display and Mysql as the database storage system. Experiments show that this solution can effectively process big data real-time streaming data and has good practical reference value in the field of information intelligence processing based on big data real-time streaming data.}, location = {Beijing, China}, series = {BDE '22}, pages = {21\u201326}, numpages = {6}, keywords = {Batch processing, Flink, Kafka, Stream processing}}
@inproceedings{10.1145/3451400.3451416,title = {Challenges and Opportunities of Using Big Data in the Management and Education of College Students}, author = {Chen Bowen , Li Meng , Lin Boxian , Wang Shihao },year = {2021}, isbn = {9781450389389}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3451400.3451416}, doi = {10.1145/3451400.3451416}, abstract = {With the rapid expansion of the Internet, we have gradually stepped into the information age and ushered in the era of big data. The emergence of big data has brought about both challenges and opportunities to education and management of college students. This paper will summarize these challenges and opportunities confronted by the administrators charged with education and management of college students in the era of big data, and propose new measures for universities to carry out education and management of college students in the era of big data, including establishing a big data platform, improving the level of informatization, and enhancing the training system for talented person, so as to increase efficiency and cultivate more high-quality talents.}, location = {London, United Kingdom}, series = {ICBDE 2021}, pages = {98\u2013102}, numpages = {5}, keywords = {student education management, big data, college students}}
@inproceedings{10.1145/3206157.3206173,title = {Research on College Students' Psychological Crisis Intervention in the Context of Big Data}, author = {Panqiu Jiang },year = {2018}, isbn = {9781450363587}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3206157.3206173}, doi = {10.1145/3206157.3206173}, abstract = {Early warning and intervention of college students' psychological crisis are becoming an important subject to college mental health education. However, there is a lack of relevance and effectiveness in warning and intervention of college students' psychological crisis. With the development of big data mining techniques, the application of using big data technology in the early warning and intervention of college students' psychological crisis will improve the accuracy of college students' psychological crisis detection and establish an effective model of crisis early warning in order to make risk intervention in time. This paper discusses the application of big data in the field of the early warning and intervention of college students 'psychological crisis and establishes an effective countermeasure of early warning and intervention of psychological crisis and builds the mental health education team so as to dynamically grasp the condition of their psychological health to effectively develop mental health education.}, location = {Honolulu, HI, USA}, series = {ICBDE '18}, pages = {33\u201337}, numpages = {5}, keywords = {psychological crisis intervention, Big data, college student}}
@inproceedings{10.1145/3148055.3148060,title = {Managing Variant Calling Files the Big Data Way: Using HDFS and Apache Parquet}, author = {Boufea Aikaterini , Finkers Richard , van Kaauwen Martijn , Kramer Mark , Athanasiadis Ioannis N. },year = {2017}, isbn = {9781450355490}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3148055.3148060}, doi = {10.1145/3148055.3148060}, abstract = {Big Data has been seen as a remedy for the efficient management of the ever-increasing genomic data. In this paper, we investigate the use of Apache Spark to store and process Variant Calling Files (VCF) on a Hadoop cluster. We demonstrate Tomatula, a software tool for converting VCF files to Apache Parquet storage format, and an application to query variant calling datasets. We evaluate how the wall time (i.e. time until the query answer is returned to the user) scales out on a Hadoop cluster storing VCF files, either in the original flat-file format, or using the Apache Parquet columnar storage format. Apache Parquet can compress the VCF data by around a factor of 10, and supports easier querying of VCF files as it exposes the field structure. We discuss advantages and disadvantages in terms of storage capacity and querying performance with both flat VCF files and Apache Parquet using an open plant breeding dataset. We conclude that Apache Parquet offers benefits for reducing storage size and wall time, and scales out with larger datasets.}, location = {Austin, Texas, USA}, series = {BDCAT '17}, pages = {219\u2013226}, numpages = {8}, keywords = {hdfs, big data, apache parquet, tomatula, variant calling, apache spark, bioinformatics, hadoop}}
@inproceedings{10.1145/3006299.3006306,title = {Empirical analysis of asymptotic ensemble learning for big data}, author = {Salloum Salman , Huang Joshua Zhexue , He Yulin },year = {2016}, isbn = {9781450346177}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3006299.3006306}, doi = {10.1145/3006299.3006306}, abstract = {In many application areas, data that is being generated and processed goes beyond the petabyte scale. Analyzing such an increasing massive volume of data faces computational, as well as, statistical challenges. In order to solve these challenges, distributed and parallel processing frameworks have been used for implementing scalable data analysis algorithms. Nevertheless, processing the whole big data set at one time may exceed the available computing resources and the time requirements for some applications. Thus, approximate approaches can be used to achieve asymptotic analysis results, especially when data analysis algorithms are amenable to an approximate result rather than an exact one. However, most approximation approaches require taking a random sample of the data which is a nontrivial task when working with big data sets. In this paper, we employ ensemble learning as an approach for asymptotic analysis using randomly selected subsets (i.e. data blocks) of a big data set. We propose an asymptotic ensemble learning framework which depends on block-based sampling rather than record-based sampling. In order to demonstrate the feasibility and performance of this framework, we present an empirical analysis on real data sets. In addition to the scalability advantage, the experimental results show that several blocks of a data set are enough to get approximately the same results as those from using the whole data set.}, location = {Shanghai, China}, series = {BDCAT '16}, pages = {8\u201317}, numpages = {10}, keywords = {big data, ensemble learning, asymptotic analysis, distributed and parallel processing, randomness}}
@inproceedings{10.1145/2382416.2382420,title = {Big data for security: challenges, opportunities, and examples}, author = {Manadhata Pratyusa K. },year = {2012}, isbn = {9781450316613}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/2382416.2382420}, doi = {10.1145/2382416.2382420}, abstract = {This is the age of big data. Enterprises collect large amounts of data about their operations and analyze the data to improve all aspects of their businesses. Big data for security, i.e., the analysis of very large enterprise data sets to identify actionable security information and hence to improve enterprise security, however, is a relatively unexplored area. Enterprises routinely collect terabytes of security relevant data, e.g., network logs and application logs, for several reasons such as availability of cheap storage and need for regulatory compliance and post hoc forensic analysis. But we face a situation where more is less; the more data we collect, the less is our ability to derive actionable information from the data.Our research group is trying to move toward a scenario where more is more; we aim to design and implement algorithms and systems to identify security relevant information from large enterprise datasets. The more data we collect, the more value we derive from the data. Our approach opens up new opportunities by combining data from multiple sources in an enterprise and from multiple enterprises. We, however, face many challenges, e.g., legal, privacy, and technical issues regarding scalable data collection and storage and scalable analytics platforms for security.Our group is currently focusing on several big data problems. In this talk, we will briefly describe the problems and then focus on one example - scalable and reliable identification of infected hosts in an enterprise network and of malicious domains visited by the enterprise's hosts. We model the identification problem as an inference problem over very large graphs derived from enterprise datasets. We will describe our experience of applying the inference approach to datasets collected from multiple enterprises worldwide.}, location = {Raleigh, North Carolina, USA}, series = {BADGERS '12}, pages = {3\u20134}, numpages = {2}, keywords = {data mining, inference, big data, big data analytics, malicious domain detection, malware detection}}
@inproceedings{10.1145/3341620.3341630,title = {The Role of Big Data, Data Science and Data Analytics in Financial Engineering}, author = {Chakravaram Venkamaraju , G. Vidya Sagar Rao , Srinivas Jangirala , Ratnakaram Sunitha },year = {2019}, isbn = {9781450360913}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3341620.3341630}, doi = {10.1145/3341620.3341630}, abstract = {Financial engineering is the process of creating innovative solutions for the existing financial problems of a company by using applications of mathematical methods. Financial engineering uses tools and knowledge from the fields of computer science, big data, data science, data analytics, statistics, economics and applied mathematics to address current financial issues as well as to devise new and innovative financial products. Financial Engineering is helpful in derivative pricing, financial regulation, execution, corporate finance, portfolio management, risk management, trading of structured products. Therefore, financial engineering is used by Commercial Banks, Investment Banks, Insurance companies and other fund hedging agencies. The present study focus on the role of big data, data science and data analytics in financial engineering as a successful tool at all stages of insurance business management practices. How these insurance companies are using said three data tools effectively as fasteners of financial engineering for the successful design, development and implementation of innovative business processes and products in this competitive and ever-changing insurance market with innovative product features and strategies.}, location = {Hong Kong, Hong Kong}, series = {BDE 2019}, pages = {44\u201350}, numpages = {7}, keywords = {Big Data, Data Analytics, Data Science, Insurance, Financial Engineering}}
@inproceedings{10.1145/2627534.2627561,title = {Tactical big data analytics: challenges, use cases, and solutions}, author = {Savas Onur , Sagduyu Yalin , Deng Julia , Li Jason },year = {2014}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/2627534.2627561}, doi = {10.1145/2627534.2627561}, abstract = {We discuss tactical challenges of the Big Data analytics regarding the underlying data, application space, and com- puting environment, and present a comprehensive solution framework motivated by the relevant tactical use cases. First, we summarize the unique characteristics of the Big Data problem in the Department of Defense (DoD) context and underline the main differences from the commercial Big Data problems. Then, we introduce two use cases, (i) Big Data analytics with multi-intelligence (multi-INT) sensor data and (ii) man-machine crowdsourcing using MapReduce framework. For these two use cases, we introduce Big Data analytics and cloud computing solutions in a coherent frame- work that supports tactical data, application, and computing needs.}, pages = {86\u201389}, numpages = {4}, keywords = {big data, tactical environment, algorithms, analytics, cloud computing}}
@inproceedings{10.1145/3341620,title = {Proceedings of the 2019 International Conference on Big Data Engineering},year = {2019}, isbn = {9781450360913}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, abstract = {The Big Data Era has arrived, in order to promote the communication and cooperation in the field of Big Data Engineering. 2019 International Conference on Big Data Engineering (BDE 2019) was successfully held in Regal Oriental Hotel, Hong Kong during June 11-13, 2019. BDE brought together researchers, engineers, academicians as well as industrial professionals from all over the world who are interested in Big Data and its current applications.}, location = {Hong Kong, Hong Kong}}
@inproceedings{10.1145/3481646.3481647,title = {SeDaSOMA: A Framework for Supporting Serendipitous, Data-As-A-Service-Oriented, Open Big Data Management and Analytics}, author = {Cuzzocrea Alfredo , Ciancarini Paolo },year = {2021}, isbn = {9781450390408}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3481646.3481647}, doi = {10.1145/3481646.3481647}, abstract = {This paper describes the anatomy of SeDaSOMA, a reference framework for supporting serendipitous, data-as-a-service-oriented, open big data management and analytics. The proposed framework aims at supporting advanced big data management and analytics by relying on innovative research findings and next-generation big data tools. The paper also depicts some Cloud-aware big data vertical applications of SeDaSOMA in specific scenarios that are currently of great interest.}, location = {Liverpool, United Kingdom}, series = {ICCBDC '21}, pages = {1\u20137}, numpages = {7}, keywords = {Big Data, Serendipitous Big Data Methodologies, Big Data Management, Open Big Data, Big Data Analytics, Big Data As a Service}}
@inproceedings{10.1145/3158337,title = {Big Data and the Attention Economy: Big Data (Ubiquity symposium)}, author = {Huberman Bernardo A. },year = {2017}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3158337}, doi = {10.1145/3158337}, abstract = {While attention has always been prized above money, few people have had the means to attract it to themselves. But the new digital economy has provided everyone with a loudspeaker; thus efforts at getting noticed have rapidly escalated in global society. The attention economy focuses on the mechanisms that mediate the allocation of this scarce entity. Social networks and big data play a role in determining what is noticed and acted upon.}, pages = {1\u20137}, numpages = {7}}
@inproceedings{10.1145/2896825.2896835,title = {Towards a model-driven design tool for big data architectures}, author = {Guerriero Michele , Tajfar Saeed , Tamburri Damian A. , Di Nitto Elisabetta },year = {2016}, isbn = {9781450341523}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/2896825.2896835}, doi = {10.1145/2896825.2896835}, abstract = {Big Data technologies are rapidly becoming a key enabler for modern industries. However, the entry costs inherent to \"going Big\" are considerable, ranging from learning curve, renting/buying infrastructure, etc. A key component of these costs is the time spent on learning about and designing with the many big data frameworks (e.g., Spark, Storm, HadoopMR, etc.) on the market. To reduce said costs while decreasing time-to-market we advocate the usage of Model-Driven Engineering (MDE), i.e., software engineering by means of models and their automated manipulation. This paper outlines a tool architecture to support MDE for big data applications, illustrating with a case-study.}, location = {Austin, Texas}, series = {BIGDSE '16}, pages = {37\u201343}, numpages = {7}, keywords = {big data applications design, meta-models, MDE, architecture framework, model transformation, design tool}}
@inproceedings{10.1145/3090354.3090386,title = {Toward Efficient Ranked-key Algorithm for the Web notification of Big Data Systems}, author = {Tourad Mohamedou Cheikh , Abdali Abdelmounaim },year = {2017}, isbn = {9781450348522}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3090354.3090386}, doi = {10.1145/3090354.3090386}, abstract = {The progress in information distribute on the network, and its users has drive to the evolution of notification systems (Web syndication), such as the Publish/Subscribe system (Pub/sub) that aid the user to trace information managed by the information collectors RSS1 in real time. For relevant use of the information issue from large data streams (Big Data) that currently exist on the net, the improvement of new filtering systems is necessary. Different algorithms have been developed to meet this end. In this work, we propose a new algorithm for indexing structures that will allow us to develop efficient systems.}, location = {Tetouan, Morocco}, series = {BDCA'17}, pages = {1\u20134}, numpages = {4}, keywords = {Big Data, Pub/sub, Ranked-Key, subscription indexing}}
@inproceedings{10.1109/CCGRID.2018.00100,title = {Pedigree-ing your big data: data-driven big data privacy in distributed environments}, author = {Cuzzocrea Alfredo , Damiani Ernesto },year = {2018}, isbn = {9781538658154}, publisher = {IEEE Press}, url = {https://doi.org/10.1109/CCGRID.2018.00100}, doi = {10.1109/CCGRID.2018.00100}, abstract = {This paper introduces a general framework for supporting data-driven privacy-preserving big data management in distributed environments, such as emerging Cloud settings. The proposed framework can be viewed as an alternative to classical approaches where the privacy of big data is ensured via security-inspired protocols that check several (protocol) layers in order to achieve the desired privacy. Unfortunately, this injects considerable computational overheads in the overall process, thus introducing relevant challenges to be considered. Our approach instead tries to recognize the \"pedigree\" of suitable summary data representatives computed on top of the target big data repositories, hence avoiding computational overheads due to protocol checking. We also provide a relevant realization of the framework above, the so-called Data-dRIven aggregate-PROvenance privacy-preserving big Multidimensional data (DRIPROM) framework, which specifically considers multidimensional data as the case of interest.}, location = {Washington, District of Columbia}, series = {CCGrid '18}, pages = {675\u2013681}, numpages = {7}}
@inproceedings{10.1145/3291801.3291820,title = {Research on Security and Privacy of Big Data under Cloud Computing Environment}, author = {Maohong Zhang , Aihua Yang , Hui Liu },year = {2018}, isbn = {9781450364768}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3291801.3291820}, doi = {10.1145/3291801.3291820}, abstract = {With the rapid development of computer science, Internet and information technology, the application scale of network is expanding constantly, and the data volume is increasing day by day. Therefore, the demand for data processing needs to be improved urgently, and Cloud computing and big data technology as the product of the development of computer networks came into being. However, the following data collection, storage, and the security and privacy issues in the process of use are faced with many risks. How to protect the security and privacy of cloud data has become one of the urgent problems to be solved. Aiming at the problem of security and privacy of data in cloud computing environment, the security of the data is ensured from two aspects: the storage scheme and the encryption mode of the cloud data.}, location = {Weihai, China}, series = {ICBDR 2018}, pages = {52\u201355}, numpages = {4}, keywords = {cloud data, big data, encryption, cloud computing, security and privacy, storage scheme}}
@inproceedings{10.1145/3421537.3421542,title = {Study of iPhone's Big Data, Market Share, Usage and Their Relationships}, author = {Lam Daphne Lai Fong },year = {2020}, isbn = {9781450375504}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3421537.3421542}, doi = {10.1145/3421537.3421542}, abstract = {In this paper, we will discuss different brands of iPhone of different market share, the relationships between iPhone's Big Data, market share [8] and their usage. We will have a look at their market share statistics, difference and comparison in graphs and tables mainly in HuaWei, Apple and Samsung [9]. Huawei is the first time to go ahead of Apple. We will also find that more and more people use iPhone nowadays because of its convenience. iPhone like our friends and assistant, we can use it anytime, anywhere and for many purposes. Research will be focused on how the iPhone changed the people's traditional behaviors such as sending emails, taking pictures, playing games, accessing the internet...etc, and inspire how the future iPhone can be developed by producers and used by people. Results and analysis of this study would be useful and could be extended for other kinds of data analysis, models, businesses used and commercial areas.}, location = {Singapore, Singapore}, series = {BDIOT '20}, pages = {7\u201310}, numpages = {4}, keywords = {Big Data, market share, Computer, eCommerce, Flow, usage, Facebook, iPhone}}
@inproceedings{10.1145/2808580.2808667,title = {Introducing big data topics: a multicourse experience report from Norway}, author = {Due Beathe , Kristiansen Monica , Colomo-Palacios Ricardo , Hien Dang Ha The },year = {2015}, isbn = {9781450334426}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/2808580.2808667}, doi = {10.1145/2808580.2808667}, abstract = {In the last few years we have witnessed an explosion of interest in Big Data in both academic and industry arenas. Big Data is about the capture, storage, analysis and visualization of huge volumes of data in both structured and unstructured forms generated from a myriad of applications and devices in a wide set of scenarios. Focusing on the need of academia to develop professional posing the competences that industry demands, the paper presents the approach adopted by the Faculty of Computer Sciences at \u00d8stfold University College, Norway to deploy Big Data related contents throughout its studies in the computing field. This paper describes initiatives in bachelor and master programs along with continuous education courses with regards to Big Data topics. New master courses were implemented in the 2014-2015 academic year, while bachelor and continuous education courses will be deployed the year after. Initial results in terms of course assessments and students' acceptation unveil promising perspectives for the initiative.}, location = {Porto, Portugal}, series = {TEEM '15}, pages = {565\u2013569}, numpages = {5}, keywords = {big data, education}}
@inproceedings{10.1145/3148055.3149209,title = {Quality-Aware Movie Recommendation System on Big Data}, author = {Tang Yan , Li Mingzheng , Wang Wangsong , Xuan Pengcheng , Geng Kun },year = {2017}, isbn = {9781450355490}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3148055.3149209}, doi = {10.1145/3148055.3149209}, abstract = {The movie recommendation is one of the most active application domain for recommendation systems (RS). However, with the rapid growth in the number of films, users have vastly different needs for the quality of the movie. In addition, facing big data, the traditional stand-alone RS is incapable to meet the need of an accurate and prompt recommendation. Aiming at solving these challenges, in this paper, we first parallelize the collaborative filtering to improve the computational efficiency, then we propose a quality-aware big data based movie recommendation system.}, location = {Austin, Texas, USA}, series = {BDCAT '17}, pages = {273\u2013274}, numpages = {2}, keywords = {quality-aware, recommender systems, hadoop, map-reduce}}
@inproceedings{10.1145/3277104.3277107,title = {Content-Based Textual Big Data Analysis and Compression}, author = {Gao Fei , Dutta Ananya , Liu Jiangjiang },year = {2018}, isbn = {9781450365406}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3277104.3277107}, doi = {10.1145/3277104.3277107}, abstract = {With the growing enhancement of technology and the Internet, the number of people who are using the Internet is increasing daily. Users are engaged in web searching and accessing different types of websites, such as social media, banking, etc. As a result, a large volume of data is being generated in every day. It is necessary to load this data for analysis purposes. However, memory space and transmission time are the most important factors of limited processing. In most cases, we only need to extract the important textual data from these vast raw datasets. In this work, we propose content-based compression (CBC) for textual data analysis on the basis of the Huffman Code. The data is pre-analyzed to find very high frequency words and then a shorter symbol is inserted to replace those words. This compression approach is performed in an effort to maintain the original format of the data so that, compressed data structure could be completely transparent to Hadoop platform. The algorithm is evaluated on a set of real world data sets (e.g. Amazon movie review, food review, etc.) and a 52.4% average data size reduction is obtained from the experiment. Though this gain may seem modest, this can be supplementary to all other compression optimization techniques. Furthermore, the proposed technique can be effectively applied for the big data optimization purpose.}, location = {Charleston, SC, USA}, series = {ICCBD '18}, pages = {7\u201312}, numpages = {6}, keywords = {Huffman Tree Algorithm, text-based encoding, Hadoop, Compression}}
@inproceedings{10.1145/3524383.3524442,title = {Research on the Application of Big Data in University's Public Opinion Monitoring and Processing}, author = {Cai Mingjun , Sam Francis , Asante Boadi Evans },year = {2022}, isbn = {9781450395793}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3524383.3524442}, doi = {10.1145/3524383.3524442}, abstract = {Higher educational institutions rely on reputation to attract and earn the legitimacy of the public. However, the emerging trend of public misinformation due to the chunk of information available on the internet affects public opinion formation (POF) about universities. Therefore, narrowing down on the fallouts in POF can provide evidence for managerial and policy interventions. This paper explores five-layer POF and its application with big data in university public opinion monitoring and processing. It reveals that big data technology can be actively employed to safeguard the image of university public opinion formation, but this can be inhibited by the lack of commitment to integrating multiple stakeholders on a common platform, privacy, and security concerns. The paper recommends collaboration between universities and the government to increase momentum on big data with requisite actions for mutual benefits.}, location = {Shanghai, China}, series = {ICBDE '22}, pages = {121\u2013126}, numpages = {6}, keywords = {public opinion system, university public opinion, Big data, data analysis}}
@inproceedings{10.1145/3379247.3379294,title = {Malicious SIM Cards Identification Method Based on Telecom Big Data Analytics}, author = {Feng Xiaoling , Zhang Tianming , Zhao Yue , Yu Zhi , Yan Long , Chen Bo , Song Yulun },year = {2020}, isbn = {9781450376730}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3379247.3379294}, doi = {10.1145/3379247.3379294}, abstract = {This paper presents a method that helps e-commercial enterprises enhance risk control capabilities and operate anti-fraud during online marketing events. By definition, Malicious SIM Cards (MSCs) identification in this paper aims to identify SIM cards which are utilized by malicious purposes on specified terminals at scale (e.g., SIM modem pool or bulk SMS machine), and behave significantly different from normal SIM cards, especially towards e-commercial companies' marketing events, e.g., releases of coupons. The proposed MSC identification method is implemented as a label-function-based factor matrix framework. Particularly, a set of label functions is constructed from six dimensions via telecom big data analytics, including frequency of replacement, location, card type, Call Detail Records (CDRs), ID type, in-network-period in terms of SIM cards. Subsequently, MSC labels are provided to the identified SIM cards among the entire China Unicom SIM cards, which realize an effective way for large scale commercial use. Finally, selected features' distribution of MSCs identified and normal SIM cards are illustrated for comparison purposes.}, location = {Sanya, China}, series = {ICCDE 2020}, pages = {136\u2013141}, numpages = {6}, keywords = {online-marketing, label function, telecom big data analytics, risk control, factor matrix, Malicious SIM cards}}
@inproceedings{10.1145/3226116,title = {Proceedings of 2018 International Conference on Big Data Technologies},year = {2018}, isbn = {9781450364270}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, abstract = {The aim of this conference was to influence the spawning of new areas of Big Data Technologies, to provide a great platform for researchers, academicians and industry persons of these fields to exchange new ideas and application experiences face to face, to establish business or research relations and to find global cooperation. It covered a broad range of topics in the field, such as Data Visualization and Visual Analytics, Big Data Algorithms, Applications and Services, Big Data Mining and Analytics, Big Data Processing and Querying, Natural Language Processing in Big Texts, Scalable computational intelligence tools, Evolutionary and Bio-inspired approaches for Big Data analysis, etc.}, location = {Hangzhou, China}}
@inproceedings{10.1145/2874239.2874256,title = {Era of big data: danger of descrimination}, author = {Gumbus Andra , Grodzinsky Frances },year = {2016}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/2874239.2874256}, doi = {10.1145/2874239.2874256}, abstract = {We live in a world of data collection where organizations and marketers know our income, our credit rating and history, our love life, race, ethnicity, religion, interests, travel history and plans, hobbies, health concerns, spending habits and millions of other data points about our private lives. This data, mined for our behaviors, habits, likes and dislikes, is referred to as the \"creep factor\" of big data [1]. It is estimated that data generated worldwide will be 1.3 zettabytes (ZB) by 2016. The rise of computational power plus cheaper and faster devices to capture, collect, store and process data, translates into the \"datafication\" of society [4]. This paper will examine a side effect of datafication: discrimination.}, pages = {118\u2013125}, numpages = {8}, keywords = {privacy, human resources, discrimination, big data}}
@inproceedings{10.1145/3341161.3343512,title = {Flexible compression of big data}, author = {Leung Carson , Jiang Fan , Zhang Yibin },year = {2019}, isbn = {9781450368681}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3341161.3343512}, doi = {10.1145/3341161.3343512}, abstract = {High volumes of valuable data and information can be easily collected in the current era of big data. As rich and constant sources of big data, an incredible amount of people from different social stratum take part in social networks. Hence, social networks are desired for many research topics. In social networks, users (or social entities) are often linked by some 'following' relationships. As the social networks growing, some famous users account (or social entities) might be followed by a large number of same other users. In this situation, we call those famous users as frequently followed groups, which some researchers (or businesses) may be interested in them for investigating. However, the discovery of those frequently followed groups might be difficult and challenging because the following data in social networks are usually very big but sparse (huge number of users lead to big 'following' data, but each user is likely only following a small number of other users). As a result, in this paper, we present a new compression model, which can be used during mining these very big but sparse social networks for discovering the frequently followed groups of users/social entities.}, location = {Vancouver, British Columbia, Canada}, series = {ASONAM '19}, pages = {741\u2013748}, numpages = {8}, keywords = {social network 'following' patterns mining, social networks, big data}}
@inproceedings{10.1145/3437075.3437086,title = {Tackling Big Data and Black Swans through Fractal Approach and Quantum Technology}, author = {Faccia Alessio , Mataruna-Dos-Santos Leonardo Jose , Hel\u00fa Hussein Mu\u00f1oz , Guimaraes-Mataruna Andressa Fontes },year = {2020}, isbn = {9781450375061}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3437075.3437086}, doi = {10.1145/3437075.3437086}, abstract = {Since the dawn of time, man has always tried to predict the future. Inserted in an environmental context, the knowledge of the variables that influenced his life allowed him to reap daily benefits and ultimately ensured his survival. Weather forecasts, bets on sports results, financial analysis, estimation of life span probabilities, to name just a few examples, are based on increasingly accurate estimates thanks to increasingly efficient statistical techniques and detection tools. Risk and uncertainty, however, although increasingly limited, represent an essential variable of any future event. The possibility of measuring and preventing (even if close to their occurrence) unlikely, but potentially catastrophic events, can determine extraordinary competitive advantages or even just guarantee the survival of a business or human existence. Unlikely events, but catastrophic, are the so-called \"black swans\" [1], and represent the nightmare of those who rely on the Gaussian approach, since, even if they fall into the tails of the bell, they represent a non-negligible threat. Studies on the black swan, especially after the events linked to the outbreak of the COVID-19 pandemic, have brought to light the so-called fractal approach that comes closest to the occurrence of most natural events. The analysis of big data, focused on the identification of the black swan, can follow different paths, in any case, the \"normal\" Gauss curve, as demonstrated, does not lend itself to this type of analysis, therefore most of the statistical tools which are based on this are not suitable for these analyses. This research highlights and tries to demonstrate how the fractal approach, combined with quantum technology, could really represent a great advance in the reliability of future predictions and the detection of black swans.}, location = {Manchester, United Kingdom}, series = {ICBDM 2020}, pages = {28\u201332}, numpages = {5}, keywords = {Quantum technology, Black Swans, Big Data, Fractals, Forecasting}}
@inproceedings{10.1145/3158339,title = {Big Data for Social Science Research: Big Data (Ubiquity symposium)}, author = {Birkin Mark },year = {2018}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3158339}, doi = {10.1145/3158339}, abstract = {Academic studies exploiting novel data sources are scarce. Typically, data is generated by commercial businesses or government organizations with no mandate and little motivation to share their assets with academic partners---partial exceptions include social messaging data and some sources of open data. The mobilization of citizen sensors at a massive scale has allowed for the development of impressive infrastructures. However, data availability is driving applications---problems are prioritized because data is available rather than because they are inherently important or interesting. The U.K. is addressing this through investments by the Economic and Social Research Council in its Big Data Network. A group of Administrative Data Research Centres are tasked with improving access to data sets in central government, while a group of Business and Local Government Centres are tasked with improving access to commercial and regional sources. This initiative is described. It is illustrated by examples from health care, transport, and infrastructure. In all of these cases, the integration of data is a key consideration. For social science problems relevant to policy or academic studies, it is unlikely all the answers will be found in a single novel data source, but rather a combination of sources is required. Through such synthesis great leaps are possible by exploiting models that have been constructed and refined over extended periods of time e.g., microsimulation, spatial interaction models, agents, discrete choice, and input-output models. Although interesting and valuable new methods are appearing, any suggestion that a new box of magic tricks labeled \"Big Data Analytics\" that sits easily on top of massive new datasets can radically and instantly transform our long-term understanding of society is na\u00efve and dangerous. Furthermore, the privacy and confidentiality of personal data is a great concern to both the individuals concerned and the data owners.}, pages = {1\u20137}, numpages = {7}}
@inproceedings{10.1145/3006299.3006334,title = {Spatial big data for designing large scale infrastructure: a case-study of electrical road systems}, author = {Shreenath Vinutha Magal , Meijer Sebastiaan },year = {2016}, isbn = {9781450346177}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3006299.3006334}, doi = {10.1145/3006299.3006334}, abstract = {Decision making and planning of large scale infrastructures within cities is often a long process encompassing years, between multiple institutions represented by experts that require negotiations and consensus of demands and goals. The role big data plays in such design could be crucial, by providing access to otherwise elusive information on movements of people and goods in a city which can then transparently inform the design process, especially about possible demands and related complexities on the infrastructure being planned. To harness this data, it is necessary to formulate the problem technically such that data can inform experts, by articulating their expertise through the data. In this paper we present an application to analyze millions of instances of spatial data to identify potential locations for electrical road installation(s) in a city, to aid urban planners and other relevant stakeholders in planning and designing an Electrical Road System for a city. The dataset being used is gathered from a major vehicle manufacturer in Sweden, containing millions of instances of GPS data emitted by thousands of vehicles. A plan for electrified transport system is formulated by retrieving locations suitable for both static and dynamic charging installations. We investigate the technical formulation of methods and metrics for such a complex design problem, based on criteria set by experts, thus contributing to the science of big data for design of infrastructure and to methodology of data science in an institutional context.}, location = {Shanghai, China}, series = {BDCAT '16}, pages = {143\u2013148}, numpages = {6}, keywords = {decision making, big data, spatio-temporal data, urban planning, infrastructure design}}
@inproceedings{10.1145/2479724.2479730,title = {Big data and e-government: issues, policies, and recommendations}, author = {Bertot John Carlo , Choi Heeyoon },year = {2013}, isbn = {9781450320573}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/2479724.2479730}, doi = {10.1145/2479724.2479730}, abstract = {The promises and potential of Big Data in transforming digital government services, governments, and the interaction between governments, citizens, and the business sector, are substantial. From \"smart\" government to transformational government, Big Data can foster collaboration; create real-time solutions to challenges in agriculture, health, transportation, and more; and usher in a new era of policy- and decision-making. There are, however, a range of policy challenges to address regarding Big Data, including access and dissemination; digital asset management, archiving and preservation; privacy; and security. This paper selectively reviews and analyzes the U.S. policy context regarding Big Data and offers recommendations aimed at facilitating Big Data initiatives.}, location = {Quebec, Canada}, series = {dg.o '13}, pages = {1\u201310}, numpages = {10}, keywords = {open government, big data}}
@inproceedings{10.1145/3399715.3400860,title = {Big Data Analysis, AI, and Visualization Workshop: Road Mapping Infrastructures for Artificial Intelligence Supporting Advanced Visual Big Data Analysis}, author = {Reis Thoralf , Bornschlegl Marco X. , Hemmje Matthias L. },year = {2020}, isbn = {9781450375351}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3399715.3400860}, doi = {10.1145/3399715.3400860}, abstract = {The overall scope and goal of the workshop is to bring together researchers active in the areas of Artificial Intelligence (AI), Big Data Analysis, and Visualization to achieve a road map, which can support the acceleration in research and data science activities by means of transforming, enriching, and deploying AI models and algorithms as well as intelligent advanced visual user interfaces supporting creation, configuration, management, and usage of distributed Big Data Analysis. Big Data Analysis and AI mutually support each other: AI-powered algorithms empower data scientists to analyze Big Data and thereby exploit its full potential whereas Big Data enables AI experts to comfortably design, validate, and deploy AI models. One of the workshop's objectives is the examination of the importance and necessity of a third, a more straightforward relationship of Big Data and AI: AI supporting all user stereotypes and organizations involved in Big Data Analysis on their exploration journey from raw input data to insight and effectuation.}, location = {Salerno, Italy}, series = {AVI '20}, pages = {1\u20132}, numpages = {2}, keywords = {AI2VIS4BigData, Big Data Analysis, Visualization, AI}}
@inproceedings{10.1145/3289430.3289469,title = {Research on Green Development of Shaanxi Industry Under The Background of Big Data}, author = {Yang Dongmin , Zhou Panpan , Kang Jiaxin },year = {2018}, isbn = {9781450365192}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3289430.3289469}, doi = {10.1145/3289430.3289469}, abstract = {Under the background of \"Internet +\" and supply side reform, the rapid development of industrialization and information technology has promoted the leaping development of big data industry, and the rapid development of big data industry is an important driving force for the green development of industry. Large data in all walks of life cross-weaving, as an important factor of production, plays an important role in the green development of industry. This paper briefly expounds the present situation of the green development of Shaanxi industry from three aspects of agriculture, industry and service industry in Shaanxi Province, and puts forward that large data can increase the added value of green agricultural production, promote the green transformation of industry, and innovate the green service mode. The big data industry is becoming a new economic growth pole and promoting Shaanxi industry in green transformation and upgrading.}, location = {Beijing, China}, series = {BDIOT 2018}, pages = {13\u201317}, numpages = {5}, keywords = {Green development, Industrial transformation, Big data, Green economy}}
@inproceedings{10.1145/3206157.3206163,title = {A Theoretical Credit Reporting System based on Big Data Concept: A Case study of Humen Textile Garment Enterprises}, author = {Li Guanzhi , Yang Xuan , Jun Wang , Tao Yang },year = {2018}, isbn = {9781450363587}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3206157.3206163}, doi = {10.1145/3206157.3206163}, abstract = {Combining the characteristics of the capital demand scale and cycle volatility caused by the unique seasonal and production organization complexity of the textile and garment industry in Humen- China, the root reasons of difficult financing and high financing costs of the textile and garment enterprises are analyzed, and the fundamental solutions are proposed in this paper. Meanwhile, the guiding and directing role of government in the field of big data application, especially the big data credit collection, is emphasized. The big data technology is well utilized to build big data collection, storage and processing platform based on the big data credit collection. In order to fundamentally solve the problem of financing difficulty in local small and medium-sized enterprise due to long-term data circulation and information asymmetry, a theoretical credit rating model is established and continuously optimized according to the features of textile and garment industry in this area. This report also contributes to the innovation-driven development of local textile and garment enterprises, promotes the management level of enterprises, and improves the innovation ability of business models.}, location = {Honolulu, HI, USA}, series = {ICBDE '18}, pages = {22\u201326}, numpages = {5}, keywords = {textile and garment, credit model, SMEs, Big data credit}}
@inproceedings{10.1145/3418688.3418697,title = {The Effect of Big Data Platforms on Multi-Stage Production System in Industrie 4.0}, author = {Liou Teau-Jiuan , Weng Ming-Wei , Lee Liza },year = {2020}, isbn = {9781450387866}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3418688.3418697}, doi = {10.1145/3418688.3418697}, abstract = {The aim of this paper is to analyze how Industrie 4.0 triggers changes in the business models of manufacturing SMEs (small and medium-sized enterprises) by big data platforms in selected casting manufacturer in Taiwan. A generalized model is presented to determine the optimal production run time, production rate, the advertising effort and demand with observation features that minimize the total cost per unit time. Advances in science and technology such as IoT technology, big data platform to investigate information asymmetry between manufacturer and customers. Numerical examples and sensitivity analysis are then provided by the collecting real data from Taiwan. Finally, concluding remarks are offered.}, location = {Taichung, Taiwan}, series = {ICCBD '20}, pages = {48\u201354}, numpages = {7}, keywords = {Digital transformation, Industrie 4.0, Big data, Multi-stage assembly}}
@inproceedings{10.1145/3386723.3387841,title = {Big Data security and privacy techniques}, author = {El Haourani Lamia , El Kalam Anas Abou , Ouahman Abdellah Ait },year = {2020}, isbn = {9781450376341}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3386723.3387841}, doi = {10.1145/3386723.3387841}, abstract = {Nowadays Information technologies have caused irreversible changes in many parts of our society. This development reached its climax with the advent of 'Big Data', whose economic and social benefits should not be neglected. However, 'Big Data' inherently threatens security as well as the founding pillars of personal data law, and for this reason many techniques are invented in parallel with the development of big data.in this article we will present what Big Data is, the challenges it faces in terms of privacy and security, as well as privacy and security techniques for Big Data at the level of anonymization encryption and Differential Privacy, by describing, analyzing, and comparing these methods}, location = {Marrakech, Morocco}, series = {NISS2020}, pages = {1\u20139}, numpages = {9}, keywords = {Big Data, Privacy, Security, techniques}}
@inproceedings{10.1145/3404687.3404693,title = {Research on the Big Data Platform and Its Key Technologies for the Railway Locomotive System}, author = {Xin Li , Tianyun Shi , Xiaoning Ma },year = {2020}, isbn = {9781450375474}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3404687.3404693}, doi = {10.1145/3404687.3404693}, abstract = {In order to improve the efficiency of locomotive organization and the quality of locomotive operation, this paper analyzes and discusses the big data platform and some key technologies suitable for the big data application of the railway locomotive system. Firstly, the definition of big data of the railway locomotive system is proposed, and the current data characteristics of the railway locomotive system are summarized, then the status quo and demands of big data application of the railway locomotive system are analyzed. Secondly, the overall architecture of the big data platform for the railway locomotive system is proposed. Furthermore, seven application scenarios available for the big data platform are analyzed, including locomotive running organization, high-speed railway, repair, maintenance and other fields. Finally, some key technologies, which consist of data collection system of front-line operations, locomotive equipment portrait analysis, staff portrait analysis, transmission and analysis of locomotive video, intelligent auxiliary driving system, are provided to increase efficiency of the locomotive organization and capability of safety management. The obtained results can play a positive role in the construction and application of big data of the railway locomotive system.}, location = {Chengdu, China}, series = {ICBDC '20}, pages = {6\u201312}, numpages = {7}, keywords = {Key technology, Railway, Application platform, Locomotive system, Big data}}
@inproceedings{10.14778/2536222.2536253,title = {Big data integration}, author = {Dong Xin Luna , Srivastava Divesh },year = {2013}, publisher = {VLDB Endowment}, url = {https://doi.org/10.14778/2536222.2536253}, doi = {10.14778/2536222.2536253}, abstract = {The Big Data era is upon us: data is being generated, collected and analyzed at an unprecedented scale, and data-driven decision making is sweeping through society. Since the value of data explodes when it can be linked and fused with other data, addressing the big data integration (BDI) challenge is critical to realizing the promise of Big Data.BDI differs from traditional data integration in many dimensions: (i) the number of data sources, even for a single domain, has grown to be in the tens of thousands, (ii) many of the data sources are very dynamic, as a huge amount of newly collected data are continuously made available, (iii) the data sources are extremely heterogeneous in their structure, with considerable variety even for substantially similar entities, and (iv) the data sources are of widely differing qualities, with significant differences in the coverage, accuracy and timeliness of data provided. This tutorial explores the progress that has been made by the data integration community on the topics of schema mapping, record linkage and data fusion in addressing these novel challenges faced by big data integration, and identifies a range of open problems for the community.}, pages = {1188\u20131189}, numpages = {2}}
@inproceedings{10.1145/2485732.2485757,title = {Big data: little software?}, author = {Gross Thomas },year = {2013}, isbn = {9781450321167}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/2485732.2485757}, doi = {10.1145/2485732.2485757}, abstract = {The steps of accessing, storing, and transmitting \"Big Data\" raise many interesting problems. But big data sets also amplify any system or software inefficiencies when large data sets require processing. So the efficiency of the generate code (and the runtime system) is crucial if we want to see widespread use of applications based on big data.Adaptive software exploits platform and data properties to custom-tailor program executions to the current environment. However, modern platforms have many features that make it difficult to support adaptive software. Multi-core systems with a non-uniform memory architecture expose various asymmetries and complicate the runtime system's task of data management, yet even modest multi-processors exhibit NUMA properties. Processor features like prefetchers are difficult to model by a compiler and may influence the execution in unexpected ways. Finally, performance monitoring units are supposed to allow a (just-in-time) compiler to obtain the information needed to adapt the generated code. But current performance monitoring units are incomplete and, worse, subject to change over time. An adaptive software system needs performance data that is readily available, reliable, and stable.In this talk I will discuss our experiences in modeling modern systems and argue for portable performance monitoring units that allow higher levels of the software tool chain to rely on live performance data.}, location = {Haifa, Israel}, series = {SYSTOR '13}, pages = {1}, numpages = {1}}
@inproceedings{10.1145/2331042.2331054,title = {Big data and internships at Cloudera}, author = {Chen Yanpei , Ferguson Andrew , Martin Brian , Wang Andrew , Wendell Patrick },year = {2012}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/2331042.2331054}, doi = {10.1145/2331042.2331054}, abstract = {Students working in the big data space get uniquely valuable experiences and perspectives by taking industrial internships, which can help further their research agendas.}, pages = {35\u201337}, numpages = {3}}