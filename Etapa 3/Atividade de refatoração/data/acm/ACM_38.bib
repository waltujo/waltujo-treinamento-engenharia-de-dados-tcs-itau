@inproceedings{10.1145/3510858.3510892,title = {Research on E-commerce Big Data Classification and Mining Algorithm Based on BP Neural Network Technology}, author = {Wang Ye },year = {2021}, isbn = {9781450390422}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3510858.3510892}, doi = {10.1145/3510858.3510892}, abstract = {With the development of the Internet, with the gradual increase of people's needs, more and more people are engaged in various activities on the Internet, such as online transactions. This article mainly studies the classification and mining algorithm of e-commerce big data based on BP neural network technology. Take user movie rating data as the object of analysis and mining, and use platform functions to complete the whole process of data from preprocessing to data mining to result data storage. According to the requirements of the platform design modules and functions, the construction process from the installation of the cluster dependent tool software, node communication, cluster configuration to the final operation monitoring was completed, and the experimental environment of the e-commerce big data platform was established. According to the real open source movie rating data, according to the BP neural network algorithm, relying on the function of the module, the whole recommendation task from data processing, algorithm mining to the final result generation is completed. Through the comparison of speedup, accuracy, recall and coverage indicators, it can be seen that when the experimental data set is 100K, the recommendation efficiency in the cluster environment is not improved. The results show that the BP neural network improves the efficiency of the e-commerce big data platform and the accuracy of task execution results.}, location = {Changsha, China}, series = {ICASIT 2021}, pages = {78\u201381}, numpages = {4}}
@inproceedings{10.1145/3482632.3484037,title = {The Construction and Research of Enterprise Accounting Data Analysis Platform under Big Data}, author = {Sun Li , Wen Tao },year = {2021}, isbn = {9781450390255}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3482632.3484037}, doi = {10.1145/3482632.3484037}, location = {Dalian, China}, series = {ICISCAE 2021}, pages = {1777\u20131780}, numpages = {4}}
@inproceedings{10.1145/3482632.3484103,title = {The Application and Research of Big Data in Internet Learning and Information Processing}, author = {Hu Bin , Liang Sha },year = {2021}, isbn = {9781450390255}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3482632.3484103}, doi = {10.1145/3482632.3484103}, location = {Dalian, China}, series = {ICISCAE 2021}, pages = {2080\u20132084}, numpages = {5}}
@inproceedings{10.1145/3465631.3465938,title = {Innovation of College Physical Education Teaching Mode in the Era of Big Data}, author = {Zou Wei , Ding Wen , Shan Xinru , Wu Xinge },year = {2021}, isbn = {9781450385015}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3465631.3465938}, doi = {10.1145/3465631.3465938}, abstract = {NOTICE OF RETRACTION: While investigating potential publication-related misconduct in connection with the ICIMTech 2021 Conference Proceedings, serious concerns were raised that cast doubt on the integrity of the peer-review process and all papers published in the Proceedings of this Conference. The integrity of the entire Conference has been called into question. As a result, of its investigation, ACM has decided to retract the Entire Conference Proceedings and all related papers from the ACM Digital Library.None of the papers from this Proceeding should be cited in the literature because of the questionable integrity of the peer review process for this Conference.}, location = {Jakarta, Indonesia}, series = {ICIMTECH 21}, pages = {1\u20135}, numpages = {5}}
@inproceedings{10.1145/3490700.3490705,title = {Research on the Influence of Transportation Network Centrality on Housing Price Based on Big Data}, author = {Gao Feng , Zhang Zhibin },year = {2021}, isbn = {9781450385084}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3490700.3490705}, doi = {10.1145/3490700.3490705}, abstract = {Based on the big data of transportation network and housing price, geographic weighted regression is used to measure the degree of difference in the impact of urban road network and public transportation network centrality on housing prices. The results show that the degree of influence of the public transport network on housing prices is generally higher than that of the road network; the betweenness of the public transport network has the greatest impact on housing prices, followed by the direct centrality of the road network, the proximity centrality of the public transport network, the proximity centrality of the road network, and the public transport network. Network direct centrality, road network between centrality. Lanzhou's urban housing prices have strong traffic-oriented characteristics, and differentiated traffic improvement plans should be formulated according to the characteristics of the traffic network of different land parcels.}, location = {Xi&apos;an, China}, series = {ICACS '21}, pages = {28\u201332}, numpages = {5}, keywords = {Geographically weighted regression, House price, Urban Network Analysis, Lanzhou}}
@inproceedings{10.1145/3468264.3468613,title = {Would you like a quick peek? providing logging support to monitor data processing in big data applications}, author = {Wang Zehao , Zhang Haoxiang , Chen Tse-Hsun (Peter) , Wang Shaowei },year = {2021}, isbn = {9781450385626}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3468264.3468613}, doi = {10.1145/3468264.3468613}, abstract = {To analyze large-scale data efficiently, developers have created various big data processing frameworks (e.g., Apache Spark). These big data processing frameworks provide abstractions to developers so that they can focus on implementing the data analysis logic. In traditional software systems, developers leverage logging to monitor applications and record intermediate states to assist workload understanding and issue diagnosis. However, due to the abstraction and the peculiarity of big data frameworks, there is currently no effective monitoring approach for big data applications. In this paper, we first manually study 1,000 randomly sampled Spark-related questions on Stack Overflow to study their root causes and the type of information, if recorded, that can assist developers with motioning and diagnosis. Then, we design an approach, DPLOG, which assists developers with monitoring Spark applications. DPLOG leverages statistical sampling to minimize performance overhead and provides intermediate information and hint/warning messages for each data processing step of a chained method pipeline. We evaluate DPLOG on six benchmarking programs and find that DPLOG has a relatively small overhead (i.e., less than 10% increase in response time when processing 5GB data) compared to without using DPLOG, and reduce the overhead by over 500% compared to the baseline. Our user study with 20 developers shows that DPLOG can reduce the needed time to debug big data applications by 63% and the participants give DPLOG an average of 4.85/5 for its usefulness. The idea of DPLOG may be applied to other big data processing frameworks, and our study sheds light on future research opportunities in assisting developers with monitoring big data applications.}, location = {Athens, Greece}, series = {ESEC/FSE 2021}, pages = {516\u2013526}, numpages = {11}, keywords = {Monitoring, Logging, Apache Spark}}
@inproceedings{10.1145/3465631.3465642,title = {Sports Consumer Behavior Based on Integrated Data in the Context of Big Data}, author = {Song Youkai },year = {2021}, isbn = {9781450385015}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3465631.3465642}, doi = {10.1145/3465631.3465642}, abstract = {NOTICE OF RETRACTION: While investigating potential publication-related misconduct in connection with the ICIMTech 2021 Conference Proceedings, serious concerns were raised that cast doubt on the integrity of the peer-review process and all papers published in the Proceedings of this Conference. The integrity of the entire Conference has been called into question. As a result, of its investigation, ACM has decided to retract the Entire Conference Proceedings and all related papers from the ACM Digital Library.None of the papers from this Proceeding should be cited in the literature because of the questionable integrity of the peer review process for this Conference.}, location = {Jakarta, Indonesia}, series = {ICIMTECH 21}, pages = {1\u20134}, numpages = {4}, keywords = {Keywords}}
@inproceedings{10.1145/2030112.2030244,title = {2nd workshop on research in the large. using app stores, wide distribution channels and big data in ubicomp research}, author = {Cramer Henriette , Rost Mattias , Bentley Frank , Shamma David Ayman },year = {2011}, isbn = {9781450306300}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/2030112.2030244}, doi = {10.1145/2030112.2030244}, abstract = {With the proliferation of app stores and the advancement of mobile devices, research that might have only been tested with a dozen participants in the past can now be released to millions. This offers huge opportunities, but also requires adaptations of existing methods in dealing with large deployments and making sense of large data sets. This workshop provides a forum for researchers to exchange experiences and strategies for wide distribution of applications as well as gathering and analyzing large scale data sets.}, location = {Beijing, China}, series = {UbiComp '11}, pages = {619\u2013620}, numpages = {2}, keywords = {big data, distribution channels, app stores, research in the large, research methods}}
@inproceedings{10.1145/3465631.3465841,title = {Association of Data Sharing and Intellectual Property Protection in the Big Data Era}, author = {Yang Xiaojing },year = {2021}, isbn = {9781450385015}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3465631.3465841}, doi = {10.1145/3465631.3465841}, abstract = {NOTICE OF RETRACTION: While investigating potential publication-related misconduct in connection with the ICIMTech 2021 Conference Proceedings, serious concerns were raised that cast doubt on the integrity of the peer-review process and all papers published in the Proceedings of this Conference. The integrity of the entire Conference has been called into question. As a result, of its investigation, ACM has decided to retract the Entire Conference Proceedings and all related papers from the ACM Digital Library.None of the papers from this Proceeding should be cited in the literature because of the questionable integrity of the peer review process for this Conference.}, location = {Jakarta, Indonesia}, series = {ICIMTECH 21}, pages = {1\u20135}, numpages = {5}}
@inproceedings{10.1145/3077286.3077294,title = {An Artificial Neural Network-based Stock Trading System Using Technical Analysis and Big Data Framework}, author = {Sezer Omer Berat , Ozbayoglu A. Murat , Dogdu Erdogan },year = {2017}, isbn = {9781450350242}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3077286.3077294}, doi = {10.1145/3077286.3077294}, abstract = {In this paper, a neural network-based stock price prediction and trading system using technical analysis indicators is presented. The model developed first converts the financial time series data into a series of buy-sell-hold trigger signals using the most commonly preferred technical analysis indicators. Then, a Multilayer Perceptron (MLP) artificial neural network (ANN) model is trained in the learning stage on the daily stock prices between 1997 and 2007 for all of the Dow30 stocks. Apache Spark big data framework is used in the training stage. The trained model is then tested with data from 2007 to 2017. The results indicate that by choosing the most appropriate technical indicators, the neural network model can achieve comparable results against the Buy and Hold strategy in most of the cases. Furthermore, fine tuning the technical indicators and/or optimization strategy can enhance the overall trading performance.}, location = {Kennesaw, GA, USA}, series = {ACM SE '17}, pages = {223\u2013226}, numpages = {4}, keywords = {Artificial neural network, Stock market, multi layer perceptron, algorithmic trading, technical analysis}}
@inproceedings{10.1145/3555051.3555075,title = {Improving open data quality through citizen engagement and data engineering}, author = {Garcia Saez Cesar },year = {2022}, isbn = {9781450398459}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3555051.3555075}, doi = {10.1145/3555051.3555075}, abstract = {In this paper, we will focus on improving the quality of open data offered through open data portals by engaging with citizens using open source tools. To do so, we will evaluate current open source solutions from the data engineering field, selecting those better suited towards collaborative workflows. We will propose a methodology to evaluate errors in open datasets and notify public administrations, resulting in better overall quality and more trustworthy and transparent processes.}, location = {Madrid, Spain}, series = {OpenSym '22}, pages = {1\u20133}, numpages = {3}, keywords = {open data, data engineering, citizen engagement, open government}}
@inproceedings{10.1145/3482632.3484080,title = {Research on Computer Intelligent Formative Evaluation of Students' Health Curriculum through Big Data}, author = {Li Jinglei },year = {2021}, isbn = {9781450390255}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3482632.3484080}, doi = {10.1145/3482632.3484080}, location = {Dalian, China}, series = {ICISCAE 2021}, pages = {1979\u20131984}, numpages = {6}}
@inproceedings{10.1145/3510858.3511406,title = {Optimization Algorithm of Sports Big Data Industry Architecture Based on Fuzzy Clustering Under the Background of \"Internet +\"}, author = {Fu Wencan , Li Honglin },year = {2021}, isbn = {9781450390422}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3510858.3511406}, doi = {10.1145/3510858.3511406}, abstract = {The era of big data is a broad period in which data and information resources occupy people's social life, which is characterized by openness, dynamics, sociality and universality. It will improve the technical ability in various fields of sports industry and bring unprecedented intelligence and upgrading to the progress of sports industry. Under the background of the development of big data, how to collect and extract information beneficial to its own development and improve service quality and market competitiveness of products are the key factors that determine the future development of sports industry. Based on this, this paper studies the optimization algorithm of sports big data industry architecture based on fuzzy clustering, and constructs an optimization model. Therefore, some countermeasures are put forward, such as solving the problem of sports big data storage, improving the ability of big data processing and service, introducing advanced data processing talents, establishing scientific research teams, protecting personal information, and developing sports joint innovation research.}, location = {Changsha, China}, series = {ICASIT 2021}, pages = {850\u2013854}, numpages = {5}}
@inproceedings{10.1145/3495018.3501124,title = {Artificial Intelligence and Machine Learning Algorithm Optimization Applied in Health Big Data Digitization}, author = {Zhang Jiaxin },year = {2021}, isbn = {9781450385046}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3495018.3501124}, doi = {10.1145/3495018.3501124}, abstract = {The purpose of this paper is to analyse the application of machine learning and artificial intelligence in healthcare, how AI algorithms affect the growth and the competition strategy of health care organizations, and how AI affects entry barriers and market concentration.}, location = {Manchester, United Kingdom}, series = {AIAM2021}, pages = {2477\u20132480}, numpages = {4}}
@inproceedings{10.1145/3495018.3501136,title = {Computer Big Data Technology and Mathematical Model Applied in Korean Network Learning System}, author = {Wang Yaqian },year = {2021}, isbn = {9781450385046}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3495018.3501136}, doi = {10.1145/3495018.3501136}, abstract = {In natural language processing systems (including machine translation systems), grammatical and semantic information dictionaries are essential components. From the perspective of language engineering, the article discusses the theoretical basis of the establishment of a language knowledge expression system for Korean information processing, the design concept of the system, the mathematical model of the system library structure, and the technology and strategy of how to use VC language to implement it. The interface legend of the program.}, location = {Manchester, United Kingdom}, series = {AIAM2021}, pages = {2544\u20132549}, numpages = {6}}
@inproceedings{10.1145/3495018.3501184,title = {Research on Informatization Innovation of Enterprise Financial Auditing under the Background of \"Internet+\" and Big Data}, author = {Zhang Zhou },year = {2021}, isbn = {9781450385046}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3495018.3501184}, doi = {10.1145/3495018.3501184}, abstract = {Under the background of the current era of big data, the explosive growth of enterprise data information and the characteristics of rapid diffusion, coupled with the rapid development of the information industry and the comprehensive promotion of information technology, make the construction of enterprise financial information inevitable for the development of Chinese enterprises. The choice, and then promotes the enterprise financial management to enter a new stage of development, this new stage of development is not only reflected in the use of advanced information equipment, but also in the proposed new corporate financial audit management strategy. Therefore, it is necessary to analyze and summarize the problems and shortcomings in the process of enterprise financial information construction, explore and improve the specific strategies of enterprise financial audit information under the background of big data, in order to build a complete enterprise financial audit information management innovation and realize corporate finance. The integration of information resources improves the quality and efficiency of corporate financial management.}, location = {Manchester, United Kingdom}, series = {AIAM2021}, pages = {2795\u20132798}, numpages = {4}}
@inproceedings{10.1145/3510858.3511005,title = {Written English Syntactic Complexity Analysis Based on AES System and Big-data Technology}, author = {Ran Haitao },year = {2021}, isbn = {9781450390422}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3510858.3511005}, doi = {10.1145/3510858.3511005}, abstract = {Based on the data from the Automatic Essay Scoring(AES) system, this research used Second Language Syntactic Complexity Analyzer(L2SCA) to analyze the English and non-English majors\u2019(EMJ and NEMJ)written English syntactic complexity and examined the predictive power of syntactic complexity measures on the AES scores of participants\u2019 essays. The results show that MLC, MLT and MLS in NEMJs\u2019 essays were significantly higher than those in EMJs\u2019 essays. EMJs\u2019 essays were significantly higher than NEMJs\u2019 in DC/C, DC/T, CT/T and C/T. NEMJs\u2019 essays were significantly higher than EMJs\u2019 in CP/C and CP/T. NEMJs\u2019 essays were significantly higher than EMJs\u2019 in CN/C. Subordination measures DC/C, DC/T, CT/T and C/T have predictive power on the AES scores of participants\u2019 essays.}, location = {Changsha, China}, series = {ICASIT 2021}, pages = {543\u2013548}, numpages = {6}}
@inproceedings{10.1145/3208159.3208178,title = {Automatic Identification of Performance Bottleneck for A Complex Rendering System through Big Data}, author = {Zhang Yanci , Liang Zi , Li Xiaoyao , Ren Wenjie , Liu Yanli },year = {2018}, isbn = {9781450364010}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3208159.3208178}, doi = {10.1145/3208159.3208178}, abstract = {In this paper, we present a data mining based algorithm to automatically locate performance bottlenecks at algorithm level for a complex rendering system. The basic idea is to treat the bottleneck identification problem as a variable importance analysis problem from a large volume of performance data which is generated by collecting the time costs under different combinations of algorithm level parameters. Based on the performance data set, random forest is adopted to conduct the variable importance ranking task. We also note an important fact that there might no performance bottleneck exists in the scope of the whole rendering system, but it is likely that bottlenecks could be found under some specific conditions. Thus we propose a bottleneck analysis tree to split the parameter space into many subspaces in which performance bottlenecks can be identified.}, location = {Bintan, Island, Indonesia}, series = {CGI 2018}, pages = {33\u201340}, numpages = {8}, keywords = {Performance bottleneck analysis, Performance analysis tree, Variable importance, Data mining}}
@inproceedings{10.1145/3343413.3377979,title = {Big Data, Little Data, or No Data? Why Human Interaction with Data is a Hard Problem}, author = {Borgman Christine L. },year = {2020}, isbn = {9781450368926}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3343413.3377979}, doi = {10.1145/3343413.3377979}, abstract = {Enthusiasm for big data is obscuring the complexity and diversity of data in scholarship and the challenges of human interaction and retrieval. Data practices are local, varying from field to field, individual to individual, and country to country. As the number and variety of research partners expands, so do the difficulties of sharing, reusing, and sustaining access to data. Information retrieval is hindered by the lack of agreement on what are \"data.\" Complexities of human interaction with data will be illustrated with empirical examples from environmental sciences, sensor networks, astronomy, biomedicine, and other fields. Unless larger questions of knowledge infrastructures and stewardship are addressed by research communities, \"no data\" often becomes the norm. Implications for policy and practice in the information sciences will be explored, drawing upon the presenter's book, Big Data, Little Data, No Data: Scholarship in the Networked World (MIT Press, 2015), and subsequent research.}, location = {Vancouver BC, Canada}, series = {CHIIR '20}, pages = {1}, numpages = {1}, keywords = {data science, research, scholarly communication, information policy, collaboration, science, knowledge infrastructures, data}}
@inproceedings{10.1145/3132847.3133187,title = {CleanCloud: Cleaning Big Data on Cloud}, author = {Wang Hongzhi , Ding Xiaoou , Chen Xiangying , Li Jianzhong , Gao Hong },year = {2017}, isbn = {9781450349185}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3132847.3133187}, doi = {10.1145/3132847.3133187}, abstract = {We describe CleanCloud, a system for cleaning big data based on Map-Reduce paradigm in cloud. Using Map-Reduce paradigm, the system detects and repairs various data quality problems in big data. We demonstrate the following features of CleanCloud: (a) the support for cleaning multiple data quality problems in big data; (b) a visual tool for watching the status of big data cleaning process and tuning the parameters for data cleaning; (c) the friendly interface for data input and setting as well as cleaned data collection for big data. CleanCloud is a promising system that provides scalable and effect data cleaning mechanism for big data in either files or databases.}, location = {Singapore, Singapore}, series = {CIKM '17}, pages = {2543\u20132546}, numpages = {4}, keywords = {entity resolution, parallel computing, data cleaning}}
@inproceedings{10.1145/3495018.3501067,title = {Research on Firefighter Digital Management Using Big Data Technology and Computer Mathematical Statistics}, author = {Guo Zhihan , Wang Jingbo , Kong Lingqian , Jin Ruhe , Li Xinmeng , Li Bin },year = {2021}, isbn = {9781450385046}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3495018.3501067}, doi = {10.1145/3495018.3501067}, abstract = {With the deepening reform of the national comprehensive fire fighting and rescue team, the state attaches great importance to public safety which puts forward higher requirements for the firefighters' fire fighting and rescue practical ability. In the actual combat, it is not only the rational use of tactics that affects the firefighters' fire fighting and rescue practical ability. More importantly, whether the firefighters' physical reserve and injury protection can support them to complete the rescue task in actual combat and how to scientifically manage the fire rescue team is the key to improve their combat ability. Aiming at this problem, this paper analyzes the impact of physical training and injury protection on the firefighters' fire fighting and rescue ability and puts forward the management scheme.}, location = {Manchester, United Kingdom}, series = {AIAM2021}, pages = {2141\u20132145}, numpages = {5}}
@inproceedings{10.1145/3482632.3484144,title = {Application and Development of Computer Artificial Intelligence Technology Based on Big Data Era}, author = {Zhang Hui },year = {2021}, isbn = {9781450390255}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3482632.3484144}, doi = {10.1145/3482632.3484144}, location = {Dalian, China}, series = {ICISCAE 2021}, pages = {2277\u20132280}, numpages = {4}}
@inproceedings{10.1145/3482632.3484110,title = {Design and Implementation of Archive Management System Based on Cloud Computing Big Data}, author = {Wu Zhengnan , Cheng Yuansheng },year = {2021}, isbn = {9781450390255}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3482632.3484110}, doi = {10.1145/3482632.3484110}, location = {Dalian, China}, series = {ICISCAE 2021}, pages = {2115\u20132118}, numpages = {4}}
@inproceedings{10.1145/5465.5466,title = {Data quality and due process in large interorganizational record systems}, author = {Laudon Kenneth C. },year = {1986}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/5465.5466}, doi = {10.1145/5465.5466}, abstract = {As societies have become more dependent on information systems to conduct and record transactions between organizations and individuals, interorganizational computer systems have become a widely used method of coordinating the actions of independent organizations. This article examines the quality of data in one important interorganizational system\u2014the criminal-record system of the United States.}, pages = {4\u201311}, numpages = {8}}
@inproceedings{10.5555/359640.359930,title = {Data quality in internet time, space, and communities (panel session)}, author = {Bowen Paul L. , Funk James D. , Jarke Matthias , Lee Yang W. , Wand Yair , Lee Yang W. },year = {2000}, publisher = {Association for Information Systems}, address = {USA}, location = {Brisbane, Queensland, Australia}, series = {ICIS '00}, pages = {713\u2013716}, numpages = {4}}
@inproceedings{10.1145/269012.269025,title = {The impact of poor data quality on the typical enterprise}, author = {Redman Thomas C. },year = {1998}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/269012.269025}, doi = {10.1145/269012.269025}, pages = {79\u201382}, numpages = {4}}
@inproceedings{10.1145/3465631.3465639,title = {Big Data in Rope Skipping Rehabilitation Training for Drug Addicts in Judicial Administration}, author = {Zhao Yunpeng , Yang Yongfen },year = {2021}, isbn = {9781450385015}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3465631.3465639}, doi = {10.1145/3465631.3465639}, abstract = {NOTICE OF RETRACTION: While investigating potential publication-related misconduct in connection with the ICIMTech 2021 Conference Proceedings, serious concerns were raised that cast doubt on the integrity of the peer-review process and all papers published in the Proceedings of this Conference. The integrity of the entire Conference has been called into question. As a result, of its investigation, ACM has decided to retract the Entire Conference Proceedings and all related papers from the ACM Digital Library.None of the papers from this Proceeding should be cited in the literature because of the questionable integrity of the peer review process for this Conference.}, location = {Jakarta, Indonesia}, series = {ICIMTECH 21}, pages = {1\u20134}, numpages = {4}}
@inproceedings{10.1145/3127479.3132565,title = {mBalloon: enabling elastic memory management for big data processing}, author = {Chen Wei , Pi Aidi , Rao Jia , Zhou Xiaobo },year = {2017}, isbn = {9781450350280}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3127479.3132565}, doi = {10.1145/3127479.3132565}, abstract = {Big Data processing often suffers from significant memory pressure, resulting in excessive garbage collection (GC) and out-of-memory (OOM) errors, harming system performance and reliability. Therefore, users tend to give an excessive heap size to applications to avoid job failure, causing low cluster utilization.In this paper, we demonstrate that lightweight virtualization, such as OS containers, opens up opportunities to address memory pressure: 1) tasks running in a container can be set to a large heap size to avoid OOM errors without worrying about thrashing the host machine; 2) tasks that are under memory pressure and incur significant GC activities can be temporarily \"suspended\" by depriving the hosting container's resources, and can be \"resumed\" later when other tasks complete and release their resources. We propose and develop mBalloon, an elastic memory manager, that leverages containers to flexibly and precisely control the memory usage of big data tasks. Applications running with mBalloon can survive from memory pressure, incur less GC overhead and help improve cluster utilization.}, location = {Santa Clara, California}, series = {SoCC '17}, pages = {654}, numpages = {1}, keywords = {memory management, big data, virtualization}}
@inproceedings{10.1145/1146598.1146688,title = {Data confidentiality, data quality and data integration for federal databases}, author = {Karr Alan F. },year = {2006}, publisher = {Digital Government Society of North America}, url = {https://doi.org/10.1145/1146598.1146688}, doi = {10.1145/1146598.1146688}, abstract = {The high-level goal of the research is to develop abstractions, theory and methodology and software tools that allow federal statistical agencies to disseminate useful information derived from confidential data but protect the privacy of data subjects---individuals and establishments.}, location = {San Diego, California, USA}, series = {dg.o '06}, pages = {332\u2013333}, numpages = {2}}
@inproceedings{10.1145/3465631.3465901,title = {Cultural Development of Ideological and Political Education under the Background of Big Data}, author = {Du Zhenhua },year = {2021}, isbn = {9781450385015}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3465631.3465901}, doi = {10.1145/3465631.3465901}, abstract = {NOTICE OF RETRACTION: While investigating potential publication-related misconduct in connection with the ICIMTech 2021 Conference Proceedings, serious concerns were raised that cast doubt on the integrity of the peer-review process and all papers published in the Proceedings of this Conference. The integrity of the entire Conference has been called into question. As a result, of its investigation, ACM has decided to retract the Entire Conference Proceedings and all related papers from the ACM Digital Library.None of the papers from this Proceeding should be cited in the literature because of the questionable integrity of the peer review process for this Conference.}, location = {Jakarta, Indonesia}, series = {ICIMTECH 21}, pages = {1\u20135}, numpages = {5}}
@inproceedings{10.1145/2724660.2728690,title = {Toward the Evaluation of Educational Videos using Bayesian Knowledge Tracing and Big Data}, author = {MacHardy Zachary , Pardos Zachary A. },year = {2015}, isbn = {9781450334112}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/2724660.2728690}, doi = {10.1145/2724660.2728690}, abstract = {Along with the advent of MOOCs and other online learning platforms such as Khan Academy, the role of online education has continued to grow in relation to that of traditional on-campus instruction. Rather than tackle the problem of evaluating large educational units such as entire online courses, this paper approaches a smaller problem: exploring a framework for evaluating more granular educational units, in this case, short educational videos. We have chosen to leverage an adaptation of traditional Bayesian Knowledge Tracing (BKT), intended to incorporate the usage of video content in addition to assessment activity. By exploring the change in predictive error when alternately including or omitting video activity, we suggest a metric for determining the relevance of videos to associated assessments. To validate our hypothesis and demonstrate the application of our proposed methods we use data obtained from the popular Khan Academy website.}, location = {Vancouver, BC, Canada}, series = {L@S '15}, pages = {347\u2013350}, numpages = {4}, keywords = {knowledge tracing, bayesian inference, instructional technology, educational videos, online education}}
@inproceedings{10.1145/3465631.3465840,title = {Psychological Effects in Flipped Classroom Teaching of College English Based on Big Data}, author = {Yuan Yuan , Li Yunxin },year = {2021}, isbn = {9781450385015}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3465631.3465840}, doi = {10.1145/3465631.3465840}, abstract = {NOTICE OF RETRACTION: While investigating potential publication-related misconduct in connection with the ICIMTech 2021 Conference Proceedings, serious concerns were raised that cast doubt on the integrity of the peer-review process and all papers published in the Proceedings of this Conference. The integrity of the entire Conference has been called into question. As a result, of its investigation, ACM has decided to retract the Entire Conference Proceedings and all related papers from the ACM Digital Library.None of the papers from this Proceeding should be cited in the literature because of the questionable integrity of the peer review process for this Conference.}, location = {Jakarta, Indonesia}, series = {ICIMTECH 21}, pages = {1\u20136}, numpages = {6}}
@inproceedings{10.1145/3482632.3482718,title = {Research on Education Management and Decision Optimization Based on Cloud Computing from the Perspective of Big Data}, author = {Liang Jing },year = {2021}, isbn = {9781450390255}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3482632.3482718}, doi = {10.1145/3482632.3482718}, abstract = {The development of economic globalization and information integration has spawned the arrival of big data environment, which is widely used in all fields of people's production and life. Big data has affected capital, technology, talent flow, etc., changed people's production and life, and also had a huge impact on the field of education, especially HE (Higher Education). In the education industry, information technology not only affects the educational means and technology, but also forms a new motive force and new idea for the development of education. Scientific and rational application of educational big data, optimization of educational management and teaching decision-making, and improvement of educational and teaching effects are important contents of information-based teaching reform and innovation, which can promote educational management and decision-making, and enhance the scientific level of educational management and teaching decision-making. This paper analyzes the positive and negative impacts of big data on HE management, studies the main causes of various problems, and puts forward ways to optimize HE management and decision-making based on cloud computing technology under the background of big data.}, location = {Dalian, China}, series = {ICISCAE 2021}, pages = {404\u2013407}, numpages = {4}}
@inproceedings{10.1145/3465631.3465802,title = {Path of University Network Political Education Based on AI Technology and Big Data}, author = {Wang Xu },year = {2021}, isbn = {9781450385015}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3465631.3465802}, doi = {10.1145/3465631.3465802}, abstract = {NOTICE OF RETRACTION: While investigating potential publication-related misconduct in connection with the ICIMTech 2021 Conference Proceedings, serious concerns were raised that cast doubt on the integrity of the peer-review process and all papers published in the Proceedings of this Conference. The integrity of the entire Conference has been called into question. As a result, of its investigation, ACM has decided to retract the Entire Conference Proceedings and all related papers from the ACM Digital Library.None of the papers from this Proceeding should be cited in the literature because of the questionable integrity of the peer review process for this Conference.}, location = {Jakarta, Indonesia}, series = {ICIMTECH 21}, pages = {1\u20134}, numpages = {4}}
@inproceedings{10.1145/2331042.2331051,title = {Big privacy: protecting confidentiality in big data}, author = {Machanavajjhala Ashwin , Reiter Jerome P. },year = {2012}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/2331042.2331051}, doi = {10.1145/2331042.2331051}, abstract = {Approaches from computer science and statistical science for assessing and protecting privacy in large, public data sets.}, pages = {20\u201323}, numpages = {4}}
@inproceedings{10.5555/2399776.2399818,title = {Workshop on Analytics for Big Data Generated by Healthcare and Personalized Medicine Domain}, author = {Joshi Karuna , Yesha Yelena },year = {2012}, publisher = {IBM Corp.}, address = {USA}, abstract = {Healthcare data presents a trove of information, which when combined with genomic data about a patient can be analyzed and lead to significantly improved and personalized delivery of healthcare. This data at present is very large in volume running to the order of terabytes. With the increasing adoption of digitized patient records and physician's notes, it has the potential of reaching peta (1015) or even exa (1018) bytes of data which in itself will be difficult to manage and analyze. Further, much of this data is in separate silos, which prevents it from being correlated and analyzed. However, very few providers can afford the infrastructure; both hardware and software are needed to collect, clean, curate, and analyze this data. As such, cloud-based healthcare services provide an important technique with which to make analytics driven personalized medicine services available to practitioners at the point of care. This however raises serious concerns around patient privacy, and also issues of regulatory compliance, as the data would reside with the cloud provider and outside of the confines of the physician's control.}, location = {Toronto, Ontario, Canada}, series = {CASCON '12}, pages = {267\u2013269}, numpages = {3}}
@inproceedings{10.1145/3130972,title = {Gamification of Mobile Experience Sampling Improves Data Quality and Quantity}, author = {van Berkel Niels , Goncalves Jorge , Hosio Simo , Kostakos Vassilis },year = {2017}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3130972}, doi = {10.1145/3130972}, abstract = {The Experience Sampling Method is used to capture high-quality in situ data from study participants. This method has become popular in studies involving smartphones, where it is often adapted to motivate participation through the use of gamification techniques. However, no work to date has evaluated whether gamification actually affects the quality and quantity of data collected through Experience Sampling. Our study systematically investigates the effect of gamification on the quantity and quality of experience sampling responses on smartphones. In a field study, we combine event contingent and interval contingent triggers to ask participants to describe their location. Subsequently, participants rate the quality of these entries by playing a game with a purpose. Our results indicate that participants using the gamified version of our ESM software provided significantly higher quality responses, slightly increased their response rate, and provided significantly more data on their own accord. Our findings suggest that gamifying experience sampling can improve data collection and quality in mobile settings.}, pages = {1\u201321}, numpages = {21}, keywords = {EMA, human behavior, labeling, motivation, sensing, ESM, CSCW, location, experience sampling method, crowdsensing}}
@inproceedings{10.1145/3523286.3524566,title = {Research on the Design of Medical Big Data Task Scheduling Based on SOS Algorithm: Preparation of Camera-Ready Contributions to SCITEPRESS Proceedings}, author = {Zeng Yan , Li Jianrong },year = {2022}, isbn = {9781450395755}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3523286.3524566}, doi = {10.1145/3523286.3524566}, abstract = {The medical big data information sharing platform has become the basic service method of today's medical services. The application of cloud computing has promoted the rapid development of medical informatization and improved the effectiveness of diagnosis and treatment. It is convenient, fast, and accurate. In the medical data query task, scheduling and allocation methods are important key technical algorithms. Based on the advantages of short task scheduling time, low cost, and high utilization rate of profit sources, this paper selects symbiosis algorithm as the task scheduling algorithm for medical big data. After simulation Experiments have proved that the effect is good.}, location = {Harbin, China}, series = {BIC 2022}, pages = {339\u2013344}, numpages = {6}}
@inproceedings{10.1145/1815695.1815706,title = {A new approach to \"storage management\" restrictions using the \"data quality\" concept}, author = {Biller Koby },year = {2010}, isbn = {9781605589084}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/1815695.1815706}, doi = {10.1145/1815695.1815706}, abstract = {Fragmentation of data in storage devices, a phenomenon that has attracted considerable research attention, is a major problem underlying computer slowdown and other unpredictable storage-related symptoms. This poster presents the \"Data Quality\" approach, which includes an effective new method for measuring the quality of data affected by continuous fragmentation. It also incorporates a novel way to handle the affected data, with clear advantages over the current alternatives of replacing the device or upgrading the computer. As an added benefit, use of this approach allows a general picture to be obtained of the data quality throughout an organization.}, location = {Haifa, Israel}, series = {SYSTOR '10}, pages = {1}, numpages = {1}}
@inproceedings{10.5555/1124191.1124210,title = {Data confidentiality, data quality and data integration for federal databases}, author = {Karr Alan F. },year = {2004}, publisher = {Digital Government Society of North America}, abstract = {The principal high-level goal of the research is to develop abstractions, theory and methodology and software tools that allow federal statistical agencies to disseminate useful information derived from confidential data but protect the privacy of data subjects---individuals and establishments.}, location = {Seattle, WA, USA}, series = {dg.o '04}, pages = {1\u20132}, numpages = {2}}
@inproceedings{10.1145/2691195.2691200,title = {Research experience of big data analytics: the tools for government: a case using social network in mining preferences of tourists}, author = {Peipeng Luo , Sim Rita Tse Tan },year = {2014}, isbn = {9781605586113}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/2691195.2691200}, doi = {10.1145/2691195.2691200}, abstract = {This research analyzes messages from Sina Weibo and extracts preferences of tourists using data mining tools. The data mining process, presented in this report, illustrates a good approach for the government in mining information and knowledge from the social network. Discovering association rules is one of the most important tasks in data mining. In this report, Apriori algorithm is used to find the association rules among keywords within topics resulting from the Topic Modeling Algorithm - LDA model. The results and further analysis of data collected from the social network can be used to help the government in Macao and Hong Kong to learn more about their tourists for their policy making in support of the tourism industry.}, location = {Guimaraes, Portugal}, series = {ICEGOV '14}, pages = {312\u2013315}, numpages = {4}, keywords = {chinese segmentation, preferences of tourists, apriori algorithm, topic modeling, social network}}
@inproceedings{10.1145/3318396.3318427,title = {Flipping the Learning and Teaching of Reading Strategies and Comprehension through a Cloud-based Interactive Big Data Reading Platform}, author = {Ho P. C. W. , Fok W. W. T. , Chan C. K. K. , Yeung H. H. Au , Ng H. W. , Wong S. L. , Ngai S. Y. , Kwok P. H. , Ho Y. S. , Chan K. H. },year = {2019}, isbn = {9781450362672}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3318396.3318427}, doi = {10.1145/3318396.3318427}, abstract = {This study investigates the learning approach of the designed Flipped Reading Platform (FRP) and its effects on primary school students' general Chinese reading and comprehension capabilities. This study was undertaken as part of the Quality Education Fund project in Hong Kong, titled \"Flipped Reading: Enhancing the Learning and Teaching of Reading Strategies and Comprehension in Chinese via an Interactive Cloud Platform.\"This paper presents the design of the Interactive Cloud Platform FRP, which incorporates elements of both reading strategies and learning activities, and investigates the changes in students' reading performance, applied strategies, and active learning level with the application of FRP. The results show the experimental students using the FRP in the pilot scheme generally gained more in three stages of reading comprehension, and that low-achieving students learned reading strategies better. Analysis of FRP log activities shows students' active engagement in reading and perceived competence. Different learning outcomes were also found within the experimental group, categorized by BYOD and non-BYOD classes. Implications of the study show the effectiveness of FRP, and the design demonstrates how the reading measures integrated the assessment indicators of both international and local standards in the domain of Chinese Language reading. Further research can be developed to examine individual online reading performance and learning behaviour on FRP.}, location = {Cambridge, United Kingdom}, series = {ICEIT 2019}, pages = {185\u2013191}, numpages = {7}, keywords = {Big data, reading strategy, e-Learning, Chinese Language, Flipped reading, Cloud Platform}}
@inproceedings{10.1145/2018673.2018679,title = {Data quality assurance and performance measurement of data mining for preventive maintenance of power grid}, author = {Wu Leon , Kaiser Gail , Rudin Cynthia , Anderson Roger },year = {2011}, isbn = {9781450308427}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/2018673.2018679}, doi = {10.1145/2018673.2018679}, abstract = {Ensuring reliability as the electrical grid morphs into the \"smart grid\" will require innovations in how we assess the state of the grid, for the purpose of proactive maintenance, rather than reactive maintenance; in the future, we will not only react to failures, but also try to anticipate and avoid them using predictive modeling (machine learning and data mining) techniques. To help in meeting this challenge, we present the Neutral Online Visualization-aided Autonomic evaluation framework (NOVA) for evaluating machine learning and data mining algorithms for preventive maintenance on the electrical grid. NOVA has three stages provided through a unified user interface: evaluation of input data quality, evaluation of machine learning and data mining results, and evaluation of the reliability improvement of the power grid. A prototype version of NOVA has been deployed for the power grid in New York City, and it is able to evaluate machine learning and data mining systems effectively and efficiently.}, location = {San Diego, California}, series = {KDD4Service '11}, pages = {28\u201332}, numpages = {5}, keywords = {data mining, machine learning, data quality assurance, performance measurement, preventive maintenance, power grid}}
@inproceedings{10.1145/3452446.3452669,title = {Construction of Practical Teaching System for Smart Tourism Management Major in the Era of Big Data}, author = {Hou Tingfei },year = {2021}, isbn = {9781450389815}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3452446.3452669}, doi = {10.1145/3452446.3452669}, abstract = {Under the background of Internet, big data is applied in all walks of life. The application in the field of tourism promotes the development of smart tourism. The application and promotion of smart tourism bring convenience and quickness to people's life. As a new mode, smart tourism puts forward new requirements for the teaching of tourism management major. Therefore, this paper based on the \"smart tourism\" Vocational Tourism Teaching Reform to do the relevant exploration and research.}, location = {Dalian, China}, series = {IPEC2021}, pages = {929\u2013933}, numpages = {5}, keywords = {Tourism Management, Teaching Reform, Smart Tourism, Questionnaire Survey}}
@inproceedings{10.1145/2850420,title = {Data Quality Challenges in Distributed Live-Virtual-Constructive Test Environments}, author = {Millar Jeremy R. , Hodson Douglas D. , Peterson Gilbert L. , Ahner Darryl K. },year = {2016}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/2850420}, doi = {10.1145/2850420}, pages = {1\u20133}, numpages = {3}, keywords = {performance estimation, Distributed simulation}}
@inproceedings{10.14778/2536274.2536330,title = {Automatic ontology-based user profile learning from heterogeneous web resources in a big data context}, author = {Hoppe Anett , Nicolle C. , Roxin A. },year = {2013}, publisher = {VLDB Endowment}, url = {https://doi.org/10.14778/2536274.2536330}, doi = {10.14778/2536274.2536330}, abstract = {The Web has developed to the biggest source of information and entertainment in the world. By its size, its adaptability and flexibility, it challenged our current paradigms on information sharing in several areas. By offering everybody the opportunity to release own contents in a fast and cheap way, the Web already led to a revolution of the traditional publishing world and just now, it commences to change the perspective on advertisements. With the possibility to adapt the contents displayed on a page dynamically based on the viewer's context, campaigns launched to target rough customer groups will become an element of the past. However, this new ecosystem, that relates advertisements with the user, heavily relies on the quality of the underlying user profile. This profile has to be able to model any combination of user characteristics, the relations between its composing elements and the uncertainty that stems from the automated processing of real-world data. The work at hand describes the beginnings of a PhD project that aims to tackle those issues using a combination of data analysis, ontology engineering and processing of big data resources provided by an industrial partner. The final goal is to automatically construct and populate a profile ontology for each user identified by the system. This allows to associate these users to high-value audience segments in order to drive digital marketing.}, pages = {1428\u20131433}, numpages = {6}}
@inproceedings{10.5555/1065226.1065289,title = {Data confidentiality, data quality and data integration for federal databases}, author = {Karr Alan F. },year = {2005}, publisher = {Digital Government Society of North America}, abstract = {The high-level goal of the research is to develop abstractions, theory and methodology and software tools that allow federal statistical agencies to disseminate useful information derived from confidential data but protect the privacy of data subjects---individuals and establishments.}, location = {Atlanta, Georgia, USA}, series = {dg.o '05}, pages = {217\u2013218}, numpages = {2}}
@inproceedings{10.1145/2463676.2463712,title = {BigBench: towards an industry standard benchmark for big data analytics}, author = {Ghazal Ahmad , Rabl Tilmann , Hu Minqing , Raab Francois , Poess Meikel , Crolotte Alain , Jacobsen Hans-Arno },year = {2013}, isbn = {9781450320375}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/2463676.2463712}, doi = {10.1145/2463676.2463712}, abstract = {There is a tremendous interest in big data by academia, industry and a large user base. Several commercial and open source providers unleashed a variety of products to support big data storage and processing. As these products mature, there is a need to evaluate and compare the performance of these systems.In this paper, we present BigBench, an end-to-end big data benchmark proposal. The underlying business model of BigBench is a product retailer. The proposal covers a data model and synthetic data generator that addresses the variety, velocity and volume aspects of big data systems containing structured, semi-structured and unstructured data. The structured part of the BigBench data model is adopted from the TPC-DS benchmark, which is enriched with semi-structured and unstructured data components. The semi-structured part captures registered and guest user clicks on the retailer's website. The unstructured data captures product reviews submitted online. The data generator designed for BigBench provides scalable volumes of raw data based on a scale factor. The BigBench workload is designed around a set of queries against the data model. From a business prospective, the queries cover the different categories of big data analytics proposed by McKinsey. From a technical prospective, the queries are designed to span three different dimensions based on data sources, query processing types and analytic techniques.We illustrate the feasibility of BigBench by implementing it on the Teradata Aster Database. The test includes generating and loading a 200 Gigabyte BigBench data set and testing the workload by executing the BigBench queries (written using Teradata Aster SQL-MR) and reporting their response times.}, location = {New York, New York, USA}, series = {SIGMOD '13}, pages = {1197\u20131208}, numpages = {12}, keywords = {benchmarking, big data, map reduce}}
@inproceedings{10.1145/3495018.3495329,title = {The Transformation and Upgrading Path of Shiyan Auto Parts Industry under the Background of Big Data}, author = {Ou Yangwei , Huang Rong , Sun Zimeng , Fu Xifeng , Su Wan },year = {2021}, isbn = {9781450385046}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3495018.3495329}, doi = {10.1145/3495018.3495329}, abstract = {Taking the big data as the research background, on the basis of combing the domestic and foreign research literature, combined with the actual situation of Shiyan, this paper analyses the difficulties in the process of transformation and upgrading of Shiyan auto parts industry, and puts forward the transformation and upgrading countermeasures and suggestions from the aspects of strengthening enterprise merger and reorganization, optimizing the urban structure, expanding the research and development of majority, so as to promote the automobile industry in Shiyan City healthy development of parts industry.}, location = {Manchester, United Kingdom}, series = {AIAM2021}, pages = {1037\u20131039}, numpages = {3}}
@inproceedings{10.5555/2755753.2757017,title = {SODA: software defined FPGA based accelerators for big data}, author = {Wang Chao , Li Xi , Zhou Xuehai },year = {2015}, isbn = {9783981537048}, publisher = {EDA Consortium}, address = {San Jose, CA, USA}, abstract = {FPGA has been an emerging field in novel big data architectures and systems, due to its high efficiency and low power consumption. It enables the researchers to deploy massive accelerators within one single chip. In this paper, we present a software defined FPGA based accelerators for big data, named SODA, which could reconstruct and reorganize the acceleration engines according to the requirement of the various data-intensive applications. SODA decomposes large and complex applications into coarse grained single-purpose RTL code libraries that perform specialized tasks in out-of-order hardware. We built a prototyping system with constrained shortest path Finding (CSPF) case studies to evaluate SODA framework. SODA is able to achieve up to 43.75X speedup at 128 node application. Furthermore, hardware cost of the SODA framework demonstrates that it can achieve high speedup with moderate hardware utilization.}, location = {Grenoble, France}, series = {DATE '15}, pages = {884\u2013887}, numpages = {4}, keywords = {software-defined, FPGA, big data, acceleratioin}}