@inproceedings{10.1145/2609876.2609877,title = {Big Data and the Invisible, Social Dimensions of Science}, author = {Vogel Kathleen M. },year = {2014}, isbn = {9781450329385}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/2609876.2609877}, doi = {10.1145/2609876.2609877}, abstract = {In this paper, I describe the challenges of using Big Data approaches in assessing security threats from the life sciences.}, location = {Raleigh, NC, USA}, series = {HCBDR '14}, pages = {1\u20133}, numpages = {3}, keywords = {socio-technical, tacit knowledge, life sciences, organizational context, Big Data, bioterrorism}}
@inproceedings{10.5555/2819289.2819302,title = {Big data system development: an embedded case study with a global outsourcing firm}, author = {Chen Hong-Mei , Kazman Rick , Haziyev Serge , Hrytsay Olha },year = {2015}, publisher = {IEEE Press}, abstract = {Big data system development is dramatically different from small (traditional, structured) data system development. At the end of 2014, big data deployment is still scarce and failures abound. Outsourcing has become a main strategy for many enterprises. We therefore selected an outsourcing company who has successfully deployed big data projects for our study. Our research results from analyzing 10 outsourced big data projects provide a glimpse into early adopters of big data, illuminates the challenges for system development that stem from the 5Vs of big data and crystallizes the importance of architecture design choices and technology selection. We followed a collaborative practice research (CPR) method to develop and validate a new method, called BDD. BDD is the first attempt to systematically combine architecture design with data modeling approaches to address big data system development challenges. The use of reference architectures and a technology catalog are advancements to architecture design methods and are proving to be well-suited for big data system architecture design and system development.}, location = {Florence, Italy}, series = {BIGDSE '15}, pages = {44\u201350}, numpages = {7}, keywords = {collaborative practice research, system engineering, big data, software architecture, embedded case study methodology, data system design methods}}
@inproceedings{10.1145/3366650.3366667,title = {Online Updating Algorithms of Statistical Methods for Big Data}, author = {Li Yihao , Wang Jin },year = {2019}, isbn = {9781450372909}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3366650.3366667}, doi = {10.1145/3366650.3366667}, abstract = {In this paper, we discuss online updating algorithms for Big Data. One of the main challenges of Big Data is the limitation of data storage. In the Big Data stream environment, online computation sometimes requires fast updates without the use of historical data. The focus of this research is on efficient online update algorithms for basic statistical computations, including mean, variance, covariance, skewness, kurtosis, confidence interval, test statistic, and linear regression. We demonstrate the implementation of R Language through a linear regress example.}, location = {Taichung, Taiwan}, series = {ICCBD 2019}, pages = {81\u201385}, numpages = {5}, keywords = {Sample Moment, Big Data, Online Algorithm, Linear Regression, Skewness, Kurtosis}}
@inproceedings{10.1145/3474944.3474962,title = {Research on University Education Innovation in the Big Data Era}, author = {Lv Haiyan },year = {2021}, isbn = {9781450389280}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3474944.3474962}, doi = {10.1145/3474944.3474962}, abstract = {The advent of the era of big data has provided a rare opportunity for the development of my country's college education, but also brought certain challenges. The changes in the era of big data have had a profound impact on the educational concept of college education and the cognition of college students\u2019 ideas and concepts. The media and new technologies are of great significance to the improvement of the mechanism of my country's higher education system and the advancement of education. The article elaborates on the elements of higher education innovation in the era of big data, and analyzes the problems existing in the current educational innovation mechanism of my country's colleges and universities. From the perspective of innovative education concepts, adhere to personalized services, build an efficient big data platform, and establish a high-quality professional team, the establishment of a multi-level education evaluation system and other aspects put forward targeted and operable countermeasures.}, location = {Singapore, Singapore}, series = {BDET 2021}, pages = {54\u201357}, numpages = {4}, keywords = {university education, big data, innovative research}}
@inproceedings{10.1145/3416921.3416943,title = {Uncertainty and Imprecision in Big Data Management: Models, Issues, Paradigms, and Future Research Directions}, author = {Cuzzocrea Alfredo },year = {2020}, isbn = {9781450375382}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3416921.3416943}, doi = {10.1145/3416921.3416943}, abstract = {This paper provides an overview of state-of-the-art proposals and forefront research directions in the context of uncertainty and imprecision in big data management, an emerging topic in the actual research community.}, location = {Virtual, United Kingdom}, series = {ICCBDC '20}, pages = {6\u20139}, numpages = {4}, keywords = {Imprecision in big data management, Uncertainty in big data management, Big data analytics, Big data management}}
@inproceedings{10.1145/2837060.2837105,title = {Schemes for Modeling Flexible Manufacturing Processes in Big Data Environment}, author = {Kim Kyeongsik , Lim Byung-Muk , Kim Ji-Dae , Chi Su-Young , Cho Wan-Sup , Yoo Kwan-Hee },year = {2015}, isbn = {9781450338462}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/2837060.2837105}, doi = {10.1145/2837060.2837105}, abstract = {This paper designs a flexible method for modeling manufacturing processes in big data environment. The purpose of the study is to design a modeling tool broadly used in various manufacture industry areas. To support the functionalities, we provide types of the process symbols, which can be used to facilitate convenient design for process modeling, and web-based visualization which will lead the light-weight modeling tool. This flexible modeling method is expected to be broadly used for modeling process in wider manufacture area in big data environment.}, location = {Jeju Island, Republic of Korea}, series = {BigDAS '15}, pages = {242\u2013245}, numpages = {4}, keywords = {Manufacturing Process, Web-based Design, Big Data}}
@inproceedings{10.1145/2609876.2609891,title = {User Evaluation Methodology Framework in Big Data Environments}, author = {Elm William C. },year = {2014}, isbn = {9781450329385}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/2609876.2609891}, doi = {10.1145/2609876.2609891}, abstract = {From an initial discussion of \"analytic tradecraft will be different when enabled with Big Data and Big Data enabled tools\", this HCBDR breakout group framed an initial context to ground the discussions to follow. The evaluation methodology must cover the triple of Organizational Context, Analyst(s) and Data/Tools all surrounding the Mission Needs. The instrumentation and measurement methodology must consider the holistic combination of all of these elements. Further, it must both measure what *is* occurring at those elements, as well as what is missing from each (felt to be a much more difficult task). The final recommendations include a blend of technical indicators (e.g. system session log information) as well as a sophisticated mix of ethnographic observations important to fully understanding the cognitive performance of the analyst and technology together. Several key issues (such as analysis quality assessment) remain unanswered.}, location = {Raleigh, NC, USA}, series = {HCBDR '14}, pages = {59\u201363}, numpages = {5}, keywords = {Human Centered, Joint Cognitive System, Cognitive Systems Engineering, Ethnographic, Workshop, Big Data, User Evaluation, Analysis, Methodology, Technology Enabled Tradecraft}}
@inproceedings{10.1145/3404687.3404707,title = {Optimization of Clothing Supply Standard Based on Big Data}, author = {Zhai Chenggong , Xiong Liang , Li Yan },year = {2020}, isbn = {9781450375474}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3404687.3404707}, doi = {10.1145/3404687.3404707}, abstract = {By collecting the data of the process of the clothing support, a big data analysis and mining tool set based on the business entity of the clothing support is built, which supports the typical data mining methods such as classification analysis, association analysis, clustering analysis, etc. the analysis and mining results provide support for the business competent department to control the development trend, technical trends and grass-roots officers and soldiers' feedback, and research and establish a system Unified, scientific, structure optimized, level clear and easy to operate clothing supply standard system, timely adjust the existing supply support standards to meet the needs of Logistics Command and information management, which is conducive to the improvement of the clothing supply support ability and the improvement of the clothing support scientific decision-making ability.}, location = {Chengdu, China}, series = {ICBDC '20}, pages = {18\u201322}, numpages = {5}, keywords = {Clothing Support Demand, Supply Standard, Big Data}}
@inproceedings{10.1145/2377978.2377984,title = {Application-driven energy-efficient architecture explorations for big data}, author = {Gu Xiaoyan , Hou Rui , Zhang Ke , Zhang Lixin , Wang Weiping },year = {2011}, isbn = {9781450314398}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/2377978.2377984}, doi = {10.1145/2377978.2377984}, abstract = {Building energy-efficient systems is critical for big data applications. This paper investigates and compares the energy consumption and the execution time of a typical Hadoop-based big data application running on a traditional Xeon-based cluster and an Atom-based (Micro-server) cluster. Our experimental results show that the micro-server platform is more energy-efficient than the Xeon-based platform. Our experimental results also reveal that data compression and decompression accounts for a considerable percentage of the total execution time. More precisely, data compression/decompression occupies 7-11% of the execution time of the map tasks and 37.9-41.2% of the execution time of the reduce tasks. Based on our findings, we demonstrate the necessity of using a heterogeneous architecture for energy-efficient big data processing. The desired architecture takes the advantages of both micro-server processors and hardware compression/decompression accelerators. In addition, we propose a mechanism that enables the accelerators to perform more efficient data compression/decompression.}, location = {Galveston Island, Texas, USA}, series = {ASBD '11}, pages = {34\u201340}, numpages = {7}, keywords = {performance, energy-efficient, big data}}
@inproceedings{10.1145/2383276.2383278,title = {Querying big data}, author = {Novikov Boris , Vassilieva Natalia , Yarygina Anna },year = {2012}, isbn = {9781450311939}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/2383276.2383278}, doi = {10.1145/2383276.2383278}, abstract = {The term \"Big Data\" became a buzzword and is widely used in both research and industrial worlds. Typically the concept of big data assumes a variety of different sources of information and velocity of complex analytical processing, rather than just a huge and growing volume of data. All variety, velocity, and volume create new research challenges, as nearly all techniques and tools commonly used in data processing have to be re-considered. Variety and uncertainty of big data require a mixture of exact and similarity search and grouping of complex objects based on different attributes. High-level declarative query languages are important in this context due to expressiveness and potential for optimization.In this talk we are mostly interested in an algebraic layer for complex query processing which resides between user interface (most likely, graphical) and execution engine in layered system architecture. We analyze the applicability of existing models and query languages. We describe a systematic approach to similarity handling of complex objects, simultaneous application of different similarity measures and querying paradigms, complex searching and querying, combined semi-structured and unstructured search. We introduce the adaptive abstract operations based on the concept of fuzzy set, which are needed to support uniform handling of different kinds of similarity processing. To ensure an efficient implementation, approximate algorithms with controlled quality are required to enable quality versus performance trade-off for timeliness of similarity processing. Uniform and adaptive operations enable high-level declarative definition of complex queries and provide options for optimization.}, location = {Ruse, Bulgaria}, series = {CompSysTech '12}, pages = {1\u201310}, numpages = {10}, keywords = {query processing, big data, query languages, computer systems and technologies}}
@inproceedings{10.1145/2658840.2658842,title = {A Paradigm for Learning Queries on Big Data}, author = {Bonifati Angela , Ciucanu Radu , Lemay Aur\u00e9lien , Staworko S\u0142awek },year = {2014}, isbn = {9781450331869}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/2658840.2658842}, doi = {10.1145/2658840.2658842}, abstract = {Specifying a database query using a formal query language is typically a challenging task for non-expert users. In the context of big data, this problem becomes even harder as it requires the users to deal with database instances of big sizes and hence difficult to visualize. Such instances usually lack a schema to help the users specify their queries, or have an incomplete schema as they come from disparate data sources. In this paper, we propose a novel paradigm for interactive learning of queries on big data, without assuming any knowledge of the database schema. The paradigm can be applied to different database models and a class of queries adequate to the database model. In particular, in this paper we present two instantiations that validated the proposed paradigm for learning relational join queries and for learning path queries on graph databases. Finally, we discuss the challenges of employing the paradigm for further data models and for learning cross-model schema mappings.}, location = {Hangzhou, China}, series = {Data4U '14}, pages = {7\u201312}, numpages = {6}, keywords = {learning, big data, user interactions, Query inference}}
@inproceedings{10.1145/3481646.3481649,title = {Benchmarking Apache Spark and Hadoop MapReduce on Big Data Classification}, author = {Tekdogan Taha , Cakmak Ali },year = {2021}, isbn = {9781450390408}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3481646.3481649}, doi = {10.1145/3481646.3481649}, abstract = {Most of the popular Big Data analytics tools evolved to adapt their working environment to extract valuable information from a vast amount of unstructured data. The ability of data mining techniques to filter this helpful information from Big Data led to the term \u2018Big Data Mining\u2019. Shifting the scope of data from small-size, structured, and stable data to huge volume, unstructured, and quickly changing data brings many data management challenges. Different tools cope with these challenges in their own way due to their architectural limitations. There are numerous parameters to take into consideration when choosing the right data management framework based on the task at hand. In this paper, we present a comprehensive benchmark for two widely used Big Data analytics tools, namely Apache Spark and Hadoop MapReduce, on a common data mining task, i.e., classification. We employ several evaluation metrics to compare the performance of the benchmarked frameworks, such as execution time, accuracy, and scalability. These metrics are specialized to measure the performance for classification task. To the best of our knowledge, there is no previous study in the literature that employs all these metrics while taking into consideration task-specific concerns. We show that Spark is 5 times faster than MapReduce on training the model. Nevertheless, the performance of Spark degrades when the input workload gets larger. Scaling the environment by additional clusters significantly improves the performance of Spark. However, similar enhancement is not observed in Hadoop. Machine learning utility of MapReduce tend to have better accuracy scores than that of Spark, like around 2%-3%, even in small-size data sets.}, location = {Liverpool, United Kingdom}, series = {ICCBDC '21}, pages = {15\u201320}, numpages = {6}, keywords = {Classification, Big Data, Data Mining}}
@inproceedings{10.1145/3141128.3141138,title = {A Systematic Review of Big Data Analytics Using Model Driven Engineering}, author = {Zafar Muhammad Nouman , Azam Farooque , Rehman Saad , Anwar Muhammad Waseem },year = {2017}, isbn = {9781450353434}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3141128.3141138}, doi = {10.1145/3141128.3141138}, abstract = {In this era of information technology, there is a huge and excessive amount of fully distributed, structured and unstructured data which is usually referred as 'Big Data'. This data cannot be easily and directly used for business purposes due to its excessiveness nature. Therefore, it is required to intelligently process this large amount of data to extract desired information and examine pattern to make decisions and predictions for certain business objectives. In this context, Model Driven Engineering (MDE) techniques are frequently applied for Big Data analytics. This paper investigates the latest models, approaches and tools for Big Data analytics using model driven approaches. Particularly, a Systematic Literature Review (SLR) is performed to select and analyze 24 researches published during 2010 to 2017. This leads to identify 18 models, 13 tools, and 10 approaches for big data analytics using model driven approaches. The findings of this SLR are highly valuable for the researchers, students and practitioners of the domain.}, location = {London, United Kingdom}, series = {ICCBDC 2017}, pages = {1\u20135}, numpages = {5}, keywords = {Model driven big data analytics, MDE, Big data predictive models, Big data}}
@inproceedings{10.1145/2694730.2694733,title = {Accelerating Big Data Processing on Modern Clusters}, author = {Panda Dhabaleswar K. },year = {2015}, isbn = {9781450333382}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/2694730.2694733}, doi = {10.1145/2694730.2694733}, abstract = {Modern clusters are having multi-/many-core architectures, high-performance rdma-enabled interconnects and SSD-based storage devices. Hadoop framework is extensively being used these days for Big Data processing. Spark framework is emerging for real-time analytics. Similarly, Memcached is being used in data centers with Web 2.0 environment. This talk will provide an overview of challenges in accelerating Hadoop, Spark and Memcached on modern clusters. An overview of RDMA-based designs for multiple components of Hadoop (HDFS, MapReduce, RPC and HBase), Spark and Memcached will be presented. Performance benefits of these designs on various cluster configurations will be shown. The talk will also address the need for designing benchmarks using a multi-layered and systematic approach, which can be used to evaluate the performance of these middleware.}, location = {Austin, Texas, USA}, series = {PABS '15}, pages = {1}, numpages = {1}, keywords = {acceleration, big data, hpc}}
@inproceedings{10.1145/3141128.3141149,title = {Scalable OLAP-Based Big Data Analytics over Cloud Infrastructures: Models, Issues, Algorithms}, author = {Cuzzocrea Alfredo },year = {2017}, isbn = {9781450353434}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3141128.3141149}, doi = {10.1145/3141128.3141149}, abstract = {Starting from the combination of two emerging research areas, namely OLAP-based big data analytics tools and Cloud infrastructures, this paper focuses the attention on so-called scalable OLAP-based big data analytics tools, by providing literature overview and two state-of-the-art research contributions of recent years. Acting as fundamental components, these solutions are likely to be integrated in larger OLAP-based big data analytics tools of the future.}, location = {London, United Kingdom}, series = {ICCBDC 2017}, pages = {17\u201321}, numpages = {5}, keywords = {Big Data Analytics, OLAP-Based Big Data Analytics, Scalable Big Data Analytics, Cloud and Big Data Computing}}
@inproceedings{10.1145/3377049.3377051,title = {Big Data & Data Science: A Descriptive Research on Big Data Evolution and a Proposed Combined Platform by Integrating R and Python on Hadoop for Big Data Analytics and Visualization}, author = {Tahsin Anika , Hasan Md. Manzurul },year = {2020}, isbn = {9781450377782}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3377049.3377051}, doi = {10.1145/3377049.3377051}, abstract = {In this technological era, Big Data is a new glorified term in where Data Science is the secret sauce of it. Undoubtedly, the digitalization of data is not the whole story; it is just a beginning of Data Science area of study. There was a time when the main focus was on building framework and processing of this data. After Hadoop HDFS and MapReduce resolved this issue already typically the concentration will follow to the next level. In terms of this, Big Data on Data Science becoming the most hyped solving area. At the moment of zettabytes data, R, Python, Hadoop all are in progressing phase in where integration among individual framework and tools will be highlighted and newest data handling tools are integrating with latest technology in terms of analytics competence. There will be a positivity when this integration will expose a new horizon for researchers and develop the preeminent solution based on the challenges.}, location = {Dhaka, Bangladesh}, series = {ICCA 2020}, pages = {1\u20132}, numpages = {2}, keywords = {Hadoop, Python, Data Science, Big Data, R}}
@inproceedings{10.1145/2837060.2837076,title = {Big Data Mining Applications and Services}, author = {Leung Carson K. },year = {2015}, isbn = {9781450338462}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/2837060.2837076}, doi = {10.1145/2837060.2837076}, abstract = {Data mining and analytics aims to analyze valuable data and extract implicit, previously unknown, and potentially useful information from the data. Due to advances in technology, high volumes of valuable data are generated at a high velocity in high varieties of data sources in various real-life business, scientific and engineering applications. Due to their high volumes, the quality and accuracy of these data depend on their veracity (uncertainty of data). This leads us into the new era of Big Data. This paper presents some works on big data mining and computing, especially on an important task of frequent pattern mining, which computes and mines from big data for interesting knowledge in the forms of frequently occurring sets of merchandise items in shopping markets, interesting co-located events, and/or popular individuals in social networks. The paper also shows how big data mining contributes to real-life applications and services.}, location = {Jeju Island, Republic of Korea}, series = {BigDAS '15}, pages = {1\u20138}, numpages = {8}, keywords = {Data mining, frequent patterns}}
@inproceedings{10.1145/3090354.3090363,title = {Big Data Analytics Techniques in Virtual Screening for Drug Discovery}, author = {Sid Karima , Batouche Mohamed Chawki },year = {2017}, isbn = {9781450348522}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3090354.3090363}, doi = {10.1145/3090354.3090363}, abstract = {Virtual screening (VS) is a computational method used in the drug discovery process by searching large libraries of small molecules to identify that represent leads for certain target. According to the use of information about the ligand, the target or both, virtual screening techniques are classified into ligand-based and structure-based methods. These methods can be combined to build a hierarchical schema in order to benefit the advantages of each one. With the rapid development of High-Throughput Technologies in structural biology, that allows producing massive libraries of small molecules include tens of millions of molecules, led to define VS as Big Data analytics problem. MapReduce is a parallel programming model produced by Google, designed for Large Scale Data processing. Apache Hadoop is the most widely used open source MapReduce implementation. It was for many years, the leading Big Data framework. Recently, with the emergence of Apache Spark as a Big Data processing framework, it has become the most popular, due to their improvement of some deficiencies known with Hadoop's MapReduce such as, speed, pipelining, and iterative jobs. In this paper, we review the Molecular Docking (MD) workflow. Next, we analyze the two most applied Big Data analytic tools in VS field which are Hadoop's MapReduce and Spark. We identify some known shortcomings that make Hadoop's MapReduce not suitable for MD issue, and point out the need of a novel MD workflow in Spark.}, location = {Tetouan, Morocco}, series = {BDCA'17}, pages = {1\u20137}, numpages = {7}, keywords = {Hierarchical Virtual Screening, Spark, Molecular Docking, Virtual Screening, Big Data, Hadoop, Drug Discovery, MapReduce}}
@inproceedings{10.1145/3501409.3501703,title = {Construction and Innovative Application of Chongqing Ecological Environment Big Data Platform}, author = {Huang Xiaoyan , Wang Luxiao , Hu Xiaoming , Jiang Rong , Zhang Yanjun , Fu Juanjuan , Zhang Xiumei },year = {2021}, isbn = {9781450384322}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3501409.3501703}, doi = {10.1145/3501409.3501703}, abstract = {This paper introduces the overall structure design of Chongqing Ecological Environment Big Data Platform \"1 + 5 + N\", that is, constructing a full-coverage ecological environment big data platform, deepening and expanding the comprehensive application system of five kinds of ecological environment big data, construction and improvement of multi-ecological environment business big data system. In summing up the current situation and existing problems in the construction of Chongqing ecological environment big data platform, from four aspects of top-level design, resource sharing, business integration and innovative application, this paper puts forward suggestions on the next step of Chongqing eco-environmental big data construction.}, location = {Xiamen, China}, series = {EITCE 2021}, pages = {1666\u20131669}, numpages = {4}, keywords = {Ecological Environment, big data}}
@inproceedings{10.1145/2609876.2609884,title = {Multidisciplinary Teamwork and Big Data}, author = {Paletz Susannah B. F. },year = {2014}, isbn = {9781450329385}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/2609876.2609884}, doi = {10.1145/2609876.2609884}, abstract = {In this presentation, I discuss four constructs vital to successful multidisciplinary teamwork: shared mental models, communicating unique information, conflict, and analogy. I highlight the literature and provide lessons learned for each.}, location = {Raleigh, NC, USA}, series = {HCBDR '14}, pages = {32\u201335}, numpages = {4}, keywords = {unique information, communication, conflict, Teams, unshared information, shared mental models, teamwork, disagreement, analogy}}
@inproceedings{10.1145/2928294.2928297,title = {Semantic big data for tax assessment}, author = {Bortoli Stefano , Bouquet Paolo , Pompermaier Flavio , Molinari Andrea },year = {2016}, isbn = {9781450342995}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/2928294.2928297}, doi = {10.1145/2928294.2928297}, abstract = {Semantic Big Data is about the creation of new applications exploiting the richness and flexibility of declarative semantics combined with scalable and highly distributed data management systems. In this work, we present an application scenario in which a domain ontology, Open Refine and the Okkam Entity Name System enable a frictionless and scalable data integration process leading to a knowledge base for tax assessment. Further, we introduce the concept of Entiton as a flexible and efficient data model suitable for large scale data inference and analytic tasks. We successfully tested our data processing pipeline on a real world dataset, supporting ACI Informatica in the investigation for Vehicle Excise Duty (VED) evasion in Aosta Valley region (Italy). Besides useful business intelligence indicators, we implemented a distributed temporal inference engine to unveil VED evasion and circulation ban violations. The results of the integration are presented to the tax agents in a powerful Siren Solution KiBi dashboard, enabling seamless data exploration and business intelligence.}, location = {San Francisco, California}, series = {SBD '16}, pages = {1\u20136}, numpages = {6}, keywords = {entity name system, semantic big data, inference, tax assessment}}
@inproceedings{10.1145/3335484.3335545,title = {Evaluation of Large-scale Complex Systems Effectiveness Based on Big Data}, author = {Zhi-peng Sun , Gui-ming Chen , Hui Zhang },year = {2019}, isbn = {9781450362788}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3335484.3335545}, doi = {10.1145/3335484.3335545}, abstract = {With the advent of the information age, big data technology came into being. The wide application of big data brings new opportunities and challenges to the construction of national defense and military information. Under the background of information-based joint operations characterized by large complex systems, how to scientifically and rationally plan the construction of large complex systems, and maximize the effectiveness of the complex system has become a key concern for system construction decision makers and researchers. This paper combines the application of big data in the construction of large complex systems, and focuses on the evaluation of the effectiveness of large complex systems based on big data, which can be used for reference by relevant researchers.}, location = {Guangzhou, China}, series = {ICBDC '19}, pages = {72\u201376}, numpages = {5}, keywords = {big data, large-scale complex systems, evaluation, effectiveness}}
@inproceedings{10.1145/3372938.3372977,title = {Smart Connection of User Profiles in a Big Data Context}, author = {Bensassi Ismail , Elyusufi Yasyn , El Mokhtar En-Naimi },year = {2019}, isbn = {9781450372404}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3372938.3372977}, doi = {10.1145/3372938.3372977}, abstract = {The idea we propose in this article is a follow-up to our research series in the ontology-based profiling framework. The approach relies on tracking user profile changes for user connection within a Big Data context. We have worked in our series of research on the identification and qualification of profiles in web 2.0 context based on the ontological approach and multi agent system. Among the limitations of our research is the fact that changing interests over time does not affect the relationships between profiles. The goal of our approach is to follow the change of the interests of internet users and to propose afterwards new relations having changed activities in the same direction. In order to implement this approach, we will first use the ontology approach. The ontology approach will allows describing semantic models and determine the properties, restrictions and axioms of our application domain. The ontology we propose will generate a set of domains and sub domains of activities used to identify user profiles. On the other hand, we will use the Multi Agents approach to process users' activities before classifying them in their profiles.}, location = {Rabat, Morocco}, series = {BDIoT'19}, pages = {1\u20138}, numpages = {8}, keywords = {Big Data, MAS, Profiling, Ontology}}
@inproceedings{10.1145/3010089.3016031,title = {A mixture model approach to big data clustering and classification}, author = {Hamdan Hani },year = {2016}, isbn = {9781450347792}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3010089.3016031}, doi = {10.1145/3010089.3016031}, abstract = {In this paper, the importance and advantages of binning data, for big data clustering and classification, are shown. Then, the fundamental and basic concepts of mixture models estimation from binned data are presented. A special attention is paid to the binned-EM algorithm, and its application to data clustering and classification. A feedback on the implementation and use of this algorithm is provided. The binned-EM algorithm is summarized so that it is easy to program. In order to show the usefulness and the good performances of the presented approach to big data clustering, an example of application to image segmentation is illustrated.}, location = {Blagoevgrad, Bulgaria}, series = {BDAW '16}, pages = {1\u20136}, numpages = {6}, keywords = {clustering, binned-EM algo-rithm, Big data, fuzzy clustering, classification, mixture model, binned data}}
@inproceedings{10.1145/3010089.3010100,title = {Opportunities, Threats and Future Directions in Big Data for Medical Wearables}, author = {Seref Berna , Bostanci Erkan },year = {2016}, isbn = {9781450347792}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3010089.3010100}, doi = {10.1145/3010089.3010100}, abstract = {Big data term has started to take part in our lives as a result of advanced technologies that produce unprecedented amount of data. Big data management has a critical role on smart decision making, new product developments and optimized offerings. Wearable devices and Internet of Things (IoT) devices are constantly adding more to this data, creating a crucial need for efficient storage, processing and analysis tools. These devices are used in many different areas including health, fitness, and entertainment. If we focus on health area, there are some medical wearable devices for tracking of cardiovascular, glaucoma, diabetes diseases etc. Literature presents a huge number of methods, algorithms and platforms which are carried on big data to manage and analyze it effectively. This paper aims to present a review of the developments in big data and wearable devices, and provide the state-of-the art approaches and developments on them. We summarize current challenges as well as defining new ones and then suggest solutions for these challenges.}, location = {Blagoevgrad, Bulgaria}, series = {BDAW '16}, pages = {1\u20135}, numpages = {5}, keywords = {Big data, wearable devices, solutions, challenges, medical wearables}}
@inproceedings{10.1145/2837060.2837112,title = {Safe-Return-Home Service based on Big Data Analytics}, author = {Lee Jae-Won , Jeong Ji-Seong , Kim Mihye , Yoo Kwan-Hee },year = {2015}, isbn = {9781450338462}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/2837060.2837112}, doi = {10.1145/2837060.2837112}, abstract = {In modern society, various forms of crime are constantly occurring. Accordingly, several safe-return systems for the socially vulnerable are being developed. However, those systems are mainly focused on responding to dangerous situations that have already occurred, and they do not predict the possibility of crime reflected by information about the user's surroundings in real time. This paper proposes a new safe-return-home service that allows users to be notified of, and therefore handle, possibly dangerous situations surrounding them in real time. This is accomplished by collecting and analyzing various types of big data about the user's surroundings in real time. Collected and analyzed data include the locations of users, the locations of CCTV (Closed-Circuit Television) cameras, crime/disaster/accident-related real-time news data, the locations of shelters, real-time CCTV video data, and social network service data. Through the analysis of these data, the prediction of potential surrounding dangers is visualized on user devices, and ideas for counteracting those dangers is suggested to users in real time.}, location = {Jeju Island, Republic of Korea}, series = {BigDAS '15}, pages = {270\u2013271}, numpages = {2}, keywords = {Safe-return-home Service, Big data analytics, Safe-return Service}}
@inproceedings{10.1145/2640087.2644153,title = {Computing Issues for Big Data: Theory, Systems and Applications}, author = {Hu Chunming },year = {2014}, isbn = {9781450328913}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/2640087.2644153}, doi = {10.1145/2640087.2644153}, abstract = {Big data may contain big values, but also brings lots of challenges to the computing theory, architecture, framework, knowledge discovery algorithms, and domain specific tools and applications. Beyond the 4-V or 5-V characters of big datasets, the data processing shows the features like inexact, incremental, and inductive manner. This brings new research opportunities to research community across theory, systems, algorithms, and applications. Is there some new \"theory\" for the big data? How to handle the data computing algorithms in an operatable manner? This report shares some view on new challenges identified, and covers some of the application scenarios such as micro-blog data analysis and data processing in building next generation search engines.}, location = {Beijing, China}, series = {BigDataScience '14}, pages = {1}, numpages = {1}}
@inproceedings{10.1145/3264560.3264572,title = {From Big Data to Better Behavior in Self-Driving Cars}, author = {Fathi F. , Abghour N. , Ouzzif M. },year = {2018}, isbn = {9781450364744}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3264560.3264572}, doi = {10.1145/3264560.3264572}, abstract = {Diversity and heterogeneity are one of the key aspects of big data. Including both structured and also unstructured data. Understanding and making sense of the huge amount of data requires better approaches for deduction and novel learning systems to address the different difficulties in many domains of application, especially in transportation. Autonomous cars are the future of transportation, in this paper, we will discuss the best combination with big data; text analytics, image processing and big data sensors, from unstructured data and then we will showcase how this fusion of data gathered by different sources can improve reliability and efficiency in self-driving and, may lead us to rethink a new theories and models altogether, and finally develop a behavior vehicle, Capable, like a human, to develop a better understanding from perception and intuition.}, location = {Barcelona, Spain}, series = {ICCBDC'18}, pages = {42\u201346}, numpages = {5}, keywords = {Big data, self-driving, NLP, Sensor fusion, CNN}}
@inproceedings{10.1145/2684822.2697027,title = {Big Data: New Paradigm or \"Sound and Fury, Signifying Nothing\"?}, author = {Broder Andrei , Adamic Lada , Franklin Michael , Rijke Maarten de , Xing Eric , Yu Kai },year = {2015}, isbn = {9781450333177}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/2684822.2697027}, doi = {10.1145/2684822.2697027}, abstract = {The Gartner's 2014 Hype Cycle released last August moves Big Data technology from the Peak of Inflated Expectations to the beginning of the Trough of Disillusionment when interest starts to wane as reality does not live up to previous promises. As the hype is starting to dissipate it is worth asking what Big Data (however defined) means from a scientific perspective: Did the emergence of gigantic corpora exposed the limits of classical information retrieval and data mining and led to new concepts and challenges, the way say, the study of electromagnetism showed the limits of Newtonian mechanics and led to Relativity Theory, or is it all just \"sound and fury, signifying nothing\", simply a matter of scaling up well understood technologies? To answer this question, we have assembled a distinguished panel of eminent scientists, from both Industry and Academia: Lada Adamic (Facebook), Michael Franklin (University of California at Berkeley), Maarten de Rijke (University of Amsterdam), Eric Xing (Carnegie Mellon University), and Kai Yu (Baidu) will share their point of view and take questions from the moderator and the audience.}, location = {Shanghai, China}, series = {WSDM '15}, pages = {5\u20136}, numpages = {2}, keywords = {big data}}
@inproceedings{10.1145/2663715.2669614,title = {Privacy and Security of Big Data: Current Challenges and Future Research Perspectives}, author = {Cuzzocrea Alfredo },year = {2014}, isbn = {9781450315838}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/2663715.2669614}, doi = {10.1145/2663715.2669614}, abstract = {Privacy and security of Big Data is gaining momentum in the research community, also due to emerging technologies like Cloud Computing, analytics engines and social networks. In response of this novel research challenge, several privacy and security of big data models, techniques and algorithms have been proposed recently, mostly adhering to algorithmic paradigms or model-oriented paradigms. Following this major trend, in this paper we provide an overview of state-of-the-art research issues and achievements in the field of privacy and security of big data, by highlighting open problems and actual research trends, and drawing novel research directions in this field.}, location = {Shanghai, China}, series = {PSBD '14}, pages = {45\u201347}, numpages = {3}, keywords = {privacy of big data, secure query processing over big data, security of big data, privacy-preserving analytics over big data}}
@inproceedings{10.1145/3220199.3220200,title = {Application research of big data experimental teaching platform based on OpenStack}, author = {Zhengjun Pan , Lianfen Zhao },year = {2018}, isbn = {9781450364263}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3220199.3220200}, doi = {10.1145/3220199.3220200}, abstract = {In view of the traditional cloud computing and big data experimental teaching platform in Colleges and universities can not meet the requirements of practical teaching, based on open source OpenStack, we designed and implemented an experimental teaching platform for cloud computing and big data.The platform is based on the effective use of existing laboratory soft hardware resources, through virtualization technology, can realize the flexible allocation of resources and effective management, realize the effective use of resources to maximize the sharing and meet the problem of cloud computing and big data management of experiment teaching and development and testing, and can also provide some support for cloud computing and big data scientific research.}, location = {Shenzhen, China}, series = {ICBDC '18}, pages = {1\u20134}, numpages = {4}, keywords = {OpenStack, Cloud computing, big data, experimental teaching platform}}
@inproceedings{10.1145/2379436.2379440,title = {Workload diversity and dynamics in big data analytics: implications to system designers}, author = {Chang Jichuan , Lim Kevin T. , Byrne John , Ramirez Laura , Ranganathan Parthasarathy },year = {2012}, isbn = {9781450314442}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/2379436.2379440}, doi = {10.1145/2379436.2379440}, abstract = {The emergence of big data analytics and the need for cost/energy efficient IT infrastructure motivate a new focus on data-centric designs. In this paper, we aim to better understand the design implications of data analytics systems by quantifying workload requirements and runtime dynamics. We examine four workloads representing big data analytics trends for fast decisions, total integration, deep analysis and fresh insights: an archive store, a columnar database enhanced with table compression, an analytics engine with distributed R, and a transaction/analytics hybrid system. These appliations demonstrate diverse resource requirements both within and across workloads as well as load imbalance due to data skew. Our observations suggest several directions to design balanced data analytics systems, including tight integration of heterogeneous, active data stores, support for efficient communication and data-centric load balancing.}, location = {Portland, Oregon, USA}, series = {ASBD '12}, pages = {21\u201326}, numpages = {6}, keywords = {workload diversity, balanced system designs, analytics system, system architectures, big data}}
@inproceedings{10.5555/2819289.2819294,title = {Big picture of big data software engineering: with example research challenges}, author = {Madhavji Nazim H. , Miranskyy Andriy , Kontogiannis Kostas },year = {2015}, publisher = {IEEE Press}, abstract = {In the rapidly growing field of Big Data, we note that a disproportionately larger amount of effort is being invested in infrastructure development and data analytics in comparison to applications software development -- approximately a 80:20 ratio. This prompted us to create a context model of Big Data Software Engineering (BDSE) containing various elements --- such as development practice, Big Data systems, corporate decision-making, and research --- and their relationships. The model puts into perspective where various types of stakeholders fit in. From the research perspective, we describe example challenges in BDSE, specifically requirements, architectures, and testing and maintenance.}, location = {Florence, Italy}, series = {BIGDSE '15}, pages = {11\u201314}, numpages = {4}, keywords = {research challenges, software engineering, applications, big data, context model}}
@inproceedings{10.1145/3105831.3105857,title = {Effective Big Data Visualization}, author = {Mani Murali , Fei Si },year = {2017}, isbn = {9781450352208}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3105831.3105857}, doi = {10.1145/3105831.3105857}, abstract = {In the last several years, big data analytics has found an increasing role in our everyday lives. Data visualization has long been accepted as an integral part of data analytics. However, data visualization systems are not equipped to handle the complexities typically found in big data. Our work examines effective ways of visualizing big data, while also realizing that most visualization processes are interactive. During an interactive visualization session, an analyst issues several visualization requests, each of which builds on prior visualizations. In our approach, we integrate a distributed data processing system that can effectively process big data with a visualization system that can provide effective interactive visualization but for smaller amounts of data. The analyst's current request is used to infer contextual information about the analyst such as their expertise and tolerance for delay. This information is used to carefully determine additional data that can be sent to the visualization system for decreasing the response time for future requests, thus providing a better experience for the analyst and increasing their productivity.}, location = {Bristol, United Kingdom}, series = {IDEAS '17}, pages = {298\u2013303}, numpages = {6}, keywords = {Data Analytics, Data Visualization, Big Data}}
@inproceedings{10.1145/3322134.3322137,title = {Implementation Practice of Big Data Technology in a Sharing Economy}, author = {Koberidze Aleksandr Z. },year = {2019}, isbn = {9781450361866}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3322134.3322137}, doi = {10.1145/3322134.3322137}, abstract = {This article attempts to uncover the main reasons for the need to implement and use Big Data for the effective functioning of an enterprise in the conditions of the sharing economy. As a key evidence that Big Data is a necessary element of the sharing economy, a comparative analysis of traditional and large databases are used. As a research task, an attempt was made to assess the scope, level of use and results of the implementation of Big Data in companies belonging to various market areas. In conclusion, all the advantages are revealed with which, in the context of the new economic paradigm, Big Data allows companies to respond quickly to user requests in the virtual space.}, location = {London, United Kingdom}, series = {ICBDE'19}, pages = {14\u201318}, numpages = {5}, keywords = {Crowd Funding, Crowd Lending, Big Data, Peer-To-Peer accommodation, Car Sharing, sharing economy, Peer-To-Peer}}
@inproceedings{10.1145/3358528.3358581,title = {Improved Constructions for Optimal Multi-erasure Locally Recoverable Codes for Big Data Storage}, author = {Qian Jianfa , Zhang Lina },year = {2019}, isbn = {9781450371926}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3358528.3358581}, doi = {10.1145/3358528.3358581}, abstract = {Multi-erasure locally recoverable codes play a very significant role in distributed data storage. The advantage of multi-erasure locally recoverable codes is that it has local and global erasure-correcting characteristics. Recently, based on classical algebraic geometry codes, Huang et al. constructed a family of explicit optimal multi-erasure locally recoverable codes over small finite fields F4. In this work, based on the work of Huang et al., we use cyclic codes to construct a family of new optimal multi-erasure locally recoverable codes over small finite fields F3. It turns out that our multi-erasure locally recoverable codes have smaller finite fields than the previously known results.}, location = {Jinan, China}, series = {ICBDT2019}, pages = {44\u201347}, numpages = {4}, keywords = {Multi-erasure locally recoverable code, data storage systems, optimal code}}
@inproceedings{10.1145/3408314,title = {Big Data Systems: A Software Engineering Perspective}, author = {Davoudian Ali , Liu Mengchi },year = {2020}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3408314}, doi = {10.1145/3408314}, abstract = {Big Data Systems (BDSs) are an emerging class of scalable software technologies whereby massive amounts of heterogeneous data are gathered from multiple sources, managed, analyzed (in batch, stream or hybrid fashion), and served to end-users and external applications. Such systems pose specific challenges in all phases of software development lifecycle and might become very complex by evolving data, technologies, and target value over time. Consequently, many organizations and enterprises have found it difficult to adopt BDSs. In this article, we provide insight into three major activities of software engineering in the context of BDSs as well as the choices made to tackle them regarding state-of-the-art research and industry efforts. These activities include the engineering of requirements, designing and constructing software to meet the specified requirements, and software/data quality assurance. We also disclose some open challenges of developing effective BDSs, which need attention from both researchers and practitioners.}, pages = {1\u201339}, numpages = {39}, keywords = {Big Data systems, software reference architecture, software engineering, Big Data, quality assurance, requirements engineering}}
@inproceedings{10.1145/3206157.3206177,title = {Language E-learning based on Learning Analytics in Big Data Era}, author = {Yanhui Wu },year = {2018}, isbn = {9781450363587}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3206157.3206177}, doi = {10.1145/3206157.3206177}, abstract = {Language E-learning, an online language learning mode, completely transforms the traditional learning and teaching mode. However, with the coming of Big Data era, it not only enjoys some benefits, but also is confronted with great challenges. The article first concludes the reforms Big Data brought to the world, and then introduces the definition, key elements, the applying model, main analyzing methods and tools of learning analytics. Finally, the article fully shows the implementation of learning analytics to the study of language E-learning. Through the study of learning analytics, the designer of Language E-learning can learn the learners' learning behaviors and provide the efficient learning material, tools and systems.}, location = {Honolulu, HI, USA}, series = {ICBDE '18}, pages = {106\u2013111}, numpages = {6}, keywords = {Big Data, language E-learning, learning analytics}}
@inproceedings{10.1145/3158352,title = {Big data: big data or big brother? that is the question now.}, author = {Johnson Jeffrey , Denning Peter , Delic Kemal A. , Sousa-Rodrigues David },year = {2018}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3158352}, doi = {10.1145/3158352}, abstract = {This ACM Ubiquity Symposium presented some of the current thinking about big data developments across four topical dimensions: social, technological, application, and educational. While 10 articles can hardly touch the expanse of the field, we have sought to cover the most important issues and provide useful insights for the curious reader. More than two dozen authors from academia and industry provided shared their points of view, their current focus of interest and their outlines of future research. Big digital data has changed and will change the world in many ways. It will bring some big benefits in the future, but combined with big AI and big IoT devices creates several big challenges. These must be carefully addressed and properly resolved for the future benefit of humanity.}, pages = {1\u201310}, numpages = {10}}
@inproceedings{10.1145/3175684.3175688,title = {Big Data Educational Portal for Small and Medium Sized Enterprises (SMEs)}, author = {Tan Chekfoung , Haji Mohammed },year = {2017}, isbn = {9781450354301}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3175684.3175688}, doi = {10.1145/3175684.3175688}, abstract = {Big Data refers to the massive amount of data generated from IT systems, sensors, and mobile devices. The values of big data are achieved by descriptive, predictive and prescriptive analytics. Small and Medium Sized Enterprises (SMEs) play a significant role in contributing to economic development. Big data is seen as a strategic and innovative tool for SMEs to stay competitive in the marketplace. However, there is lack of research in studying the value of big data to SMEs. Moreover, due to the shortage of quality learning platforms, SMEs have limited understanding of the potential benefits big data offers their businesses. This research aims to propose an educational portal of big data for SMEs by incorporating the pedagogy aspects. The research is underpinned by design science research. The portal contributes theoretically and methodologically by deriving the design knowledge of such portal and practically by increasing big data knowledge among SMEs.}, location = {London, United Kingdom}, series = {BDIOT2017}, pages = {11\u201315}, numpages = {5}, keywords = {Big Data, Pedagogy, Educational Portal, Design Science Research, Small and Medium Sized Enterprises}}
@inproceedings{10.1145/2811222.2811235,title = {Big Data Design}, author = {Abell\u00f3 Alberto },year = {2015}, isbn = {9781450337854}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/2811222.2811235}, doi = {10.1145/2811222.2811235}, abstract = {It is widely accepted today that Relational databases are not appropriate in highly distributed shared-nothing architectures of commodity hardware, that need to handle poorly structured heterogeneous data. This has brought the blooming of NoSQL systems with the purpose of mitigating such problem, specially in the presence of analytical workloads. Thus, the change in the data model and the new analytical needs beyond OLAP take us to rethink methods and models to design and manage these newborn repositories. In this paper, we will analyze state of the art and future research directions.}, location = {Melbourne, Australia}, series = {DOLAP '15}, pages = {35\u201338}, numpages = {4}, keywords = {big data, database design, nosql}}
@inproceedings{10.1145/3404687.3404708,title = {Research on Wartime Oil Consumption Based on Big Data}, author = {Zhai Chenggong , Su XiSheng , Zhang Hua Ping },year = {2020}, isbn = {9781450375474}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3404687.3404708}, doi = {10.1145/3404687.3404708}, abstract = {Oil consumption prediction is a pre calculation of the amount of oil consumed in a certain period of time or when completing a certain task. It is the basis of wartime oil service organization plan and an important work of wartime oil departments. The purpose of oil consumption is to determine oil reserves scientifically and reasonably, stipulate oil consumption quota, organize oil forwarding and replenishment, deploy oil support force, prepare oil support plan and provide important quantitative basis, so as to improve the accuracy, planning and initiative of oil support.}, location = {Chengdu, China}, series = {ICBDC '20}, pages = {51\u201354}, numpages = {4}, keywords = {Forecast, WartimeOil Consumption, Big Data}}
@inproceedings{10.1145/3322134.3323932,title = {New Approach of Big Data and Education: Any Term Must Be in the Characters Chessboard as a Super Matrix}, author = {Zou Xiaohui , Zou Shunpeng , Wang Xiaoqun },year = {2019}, isbn = {9781450361866}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3322134.3323932}, doi = {10.1145/3322134.3323932}, abstract = {The purpose of this paper is to introduce a new approach that must cover all the terms. Therefore, people's educational process is like making a variety of choices in a super-chessboard of language or a matrix composed of words formally. The method of redemption is: First, construct the chessboard, and then, through human-computer interaction and collaboration, generate massive amounts of big data, including various terms representing knowledge, and finally, through machine learning and man-machine interactive to analyze, compare, and query or reuse any of these terms. The result: an accurate query of terms, which can be automatically queried in multiple ways through bilingual or multi-lingual converters. The significance is that the method and its results can be used not only for machine-assisted instruction in the network environment, but also for machine-assisted intelligent text analysis and knowledge module finishing in the network environment, thus opening up view of big data and education. The new approach, because any term must be in the word matrix, each user and its agents query them very accurately and efficiently.}, location = {London, United Kingdom}, series = {ICBDE'19}, pages = {129\u2013134}, numpages = {6}, keywords = {E-education, Big Data Applications, Data Management}}
@inproceedings{10.1145/3366030.3366121,title = {Data Source Selection in Big Data Context}, author = {Safhi Hicham Moad , Frikh Bouchra , Ouhbi Brahim },year = {2019}, isbn = {9781450371797}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3366030.3366121}, doi = {10.1145/3366030.3366121}, abstract = {Big Data presents promising technological and economical opportunities. In fact, it has become the raw material of production for many organizations. Data is available in large quantities, and it continues generating abundantly. However, not all the data will have valuable knowledge. Unreliable sources provide misleading and biased information, and even reliable sources could suffer from low data quality.In this paper, we propose a novel methodology for the selectability of data sources, by both considering the presence and the absence of users' preferences. The proposed model integrates multiple factors that affect the reliability of data sources, including their quality, gain, cost and coverage. Experimental results on real world data-sets, show its capability to find the subset of relevant and reliable sources with the lowest cost.}, location = {Munich, Germany}, series = {iiWAS2019}, pages = {611\u2013616}, numpages = {6}, keywords = {Source reliability, Data quality, Big Data Source Selection, Big Data integration}}
@inproceedings{10.1145/3436286.3436404,title = {Application of Artificial Intelligence and Big Data Technology in Digital Marketing}, author = {Gao Fang , Zhang Lan },year = {2020}, isbn = {9781450376457}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3436286.3436404}, doi = {10.1145/3436286.3436404}, abstract = {At present, intelligent technologies such as artificial intelligence and big data are in full swing, and various application scenarios are gradually landing. The application of big data and artificial intelligence technologies to digital marketing has become a top priority for the development of the industry, and has been It has become a consensus and is becoming more and more popular. However, there are still many problems in the application process, the most common of which is that marketing is not accurate enough. Under this background, this article uses a hotel chain company as an example to study the precision of digital marketing, which makes the marketing effect significantly improved. The introduction of artificial intelligence and big data makes data no longer just a simple entry. These intelligent technologies fully tap the potential behind these data. These potentials have important values and significance for social development.}, location = {Johannesburg, South Africa}, series = {ISBDAI '20}, pages = {270\u2013272}, numpages = {3}, keywords = {Big data, Precision, Artificial intelligence, Digital marketing}}
@inproceedings{10.1145/3437075.3437078,title = {Implementation of Big Data Analytics: Customers Analyzing using an Association Rule Modeling in a Gold, Silver, and Precious Metal Trading Company in Indonesia}, author = {Yudhistyra Wecka Imam , Raungratanaamporn I-soon , Ratanavaraha Vatanavongs },year = {2020}, isbn = {9781450375061}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3437075.3437078}, doi = {10.1145/3437075.3437078}, abstract = {The underlying reason for this manuscript is to implement big data analytics to find meaningful patterns and offer useful insights from a large amount of big data available. Since many companies are still struggling to optimize big data to support their business, it is essential to minimize the gap between a large amount of data available now and the skills to analyze it. In addition, there is also a deficiency in related publications in scientific journals regarding the implementation of Big Data Analytics (BDA), which makes this manuscript significant. In addition, BDA is a new interesting thing (particularly in a developing country like Indonesia or other ASEAN countries), it is hard to be implemented, and this manuscript tries to resolve most of that complex problem of practice including the critical issue and leverages it in ways that could positively influence the organization's decision-making process. Finally, the results of this manuscript are some recommendations for companies in conducting big data analytics.}, location = {Manchester, United Kingdom}, series = {ICBDM 2020}, pages = {3\u20137}, numpages = {5}, keywords = {enterprise information systems, enterprise computing, association rules, analytics, knowledge discovery, Big data, modeling and simulation, machine learning, information visualization, pattern}}
@inproceedings{10.1145/3305275.3305330,title = {Research on University Education Management System Based on Big Data}, author = {Ou Xiu-ying },year = {2018}, isbn = {9781450365703}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3305275.3305330}, doi = {10.1145/3305275.3305330}, abstract = {In recent years, information technology has achieved rapid development and has been widely used in many fields. With the continuous improvement of the level of higher education and the scale of education in China, colleges and universities have paid more and more attention to the use of information technology in education management. Many universities have carried out research work on education management systems based on big data. It summarizes the related theories of big data, analyzes the importance of big data, and puts forward effective solutions according to the application status of big data in college education management system. In the overall system architecture, database security, system requirements, After detailed requirements analysis of system functions and other aspects, a system solution combining flexibility, openness and applicability was developed. For the domestic educational management systems, most of them are based on C/S or B/S single mode, they are difficult to meet the system solution requirements proposed in this paper. The system developed in this paper proposes a combination of C/S and B/S modes. Oracle and PL/SQL are used as the back-end database. The front-end development tools use Delphi2009, ASP.net, PL/SQL Developer and auxiliary software Dreamweaver5.0.}, location = {Hong Kong, Hong Kong}, series = {ISBDAI '18}, pages = {275\u2013280}, numpages = {6}, keywords = {C/S and B/S, Big data, management system, impact countermeasures, college education}}
@inproceedings{10.1145/2609876.2609878,title = {Cognitive and Organizational Challenges of Big Data in Cyber Defense}, author = {Gersh John R. , Bos Nathan },year = {2014}, isbn = {9781450329385}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/2609876.2609878}, doi = {10.1145/2609876.2609878}, abstract = {The cognitive and organizational challenges associated with `Big Data' have not received much research attention. We have begun an interview study of analysts who work in the computer network (cyber) defense (CND) area and have experienced changes in data scale affecting their analytical work. Our goal is to understand any changes in analysts' mental models of their data and their domain. We used a qualitative inquiry method, starting with relatively open-ended questions. Our interview protocol also asked analysts to describe critical incidents related to data use, and probed for previously-identified cognitive biases that may affect analysis in this domain.}, location = {Raleigh, NC, USA}, series = {HCBDR '14}, pages = {4\u20138}, numpages = {5}, keywords = {Mental models, big data, data analysis, computer network defense, cognition, organizations}}
@inproceedings{10.1145/2896825.2896828,title = {A big data framework for cloud monitoring}, author = {Zareian Saeed , Fokaefs Marios , Khazaei Hamzeh , Litoiu Marin , Zhang Xi },year = {2016}, isbn = {9781450341523}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/2896825.2896828}, doi = {10.1145/2896825.2896828}, abstract = {Elasticity is a key component of modern cloud environments and monitoring is an essential part of this process. Monitoring demonstrates several challenges including gathering metrics from a variety of layers (infrastructure, platform, application), the need for fast processing of this data to enable efficient elasticity and the proper management of this data in order to facilitate analysis of current and past data and future predictions. In this work, we classify monitoring as a big data problem and propose appropriate solutions in a layered, pluggable and extendable architecture for a monitoring component. More specifically, we propose the use of NoSQL databases as the back-end and BigQueue as a write buffer to achieve high throughput. Our evaluation shows that our monitoring is capable of achieving response time of a few hundreds of milliseconds for the insertion of hundreds of rows regardless of the underlying NoSQL database.}, location = {Austin, Texas}, series = {BIGDSE '16}, pages = {58\u201364}, numpages = {7}, keywords = {NoSQL datastores, cloud applications, big data, monitoring system, performance analysis}}
@inproceedings{10.1145/3358528.3359551,title = {Application of Recommender System in Intelligent Community under Big Data Scenario}, author = {Liu Cong , Chen Zhenxiang , Cao Dong , Shang Mingyue },year = {2019}, isbn = {9781450371926}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3358528.3359551}, doi = {10.1145/3358528.3359551}, abstract = {Nowadays, intelligent community is one of indispensable parts in social construction. The construction of intelligent community promotes the construction and development of intelligent city, which can improve residents' living quality. Eating is an important part inhuman lives. In this paper, we develop a food recommendation system. This system is based on big data, Association Rule-based Recommendation and Collaborative Filtering Recommendation. By analyzing a large number of historical user behaviors, this system recommends restaurants, supermarkets, recipes and meal delivery service.}, location = {Jinan, China}, series = {ICBDT2019}, pages = {92\u201396}, numpages = {5}, keywords = {Intelligent community, Recommender system, Big data}}